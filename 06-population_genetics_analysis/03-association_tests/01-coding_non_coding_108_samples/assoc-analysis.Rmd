---
title: "2019-02-05-pheidole-regression"
author: "EmelineFavreau"
date: "05 February 2019"
output:
  pdf_document: default
---

I tested each SNP for association with social type using logistic regression test implemented in plink, with PC1 and PC2 for covariates (related to longitude and latitude). 395,163 biallelic SNPs, in linkage equilibrium, supported by at least 75% of samples.


```{r eval = TRUE, echo = FALSE, include = FALSE}
# check the working directory
getwd() #"/Users/emeline/apocrita/2018-11-09-association_analysis_mixed_assembly/result/2019-01-03-association_analysis"
R.Version()$version.string # "R version 3.3.2 (2016-10-31)"
basic_libraries <- c("qqman", "ggplot2", "adegenet", "genetics", "pegas", "reshape2", "hierfstat")
for (lib in basic_libraries) {
        if (require(package = lib, character.only = TRUE)) {
                print("Successful")
        } else {
                print("Installing")
                install.packages(lib)
                library(lib, character.only = TRUE )
        }
}
```


# Evaluating raw p-value distribution
We remove loci in small scaffolds (<5kb), for a remaining  351,865 SNPs.

```{r, eval = TRUE, echo = FALSE}
plink_output <- read.csv("result/pheidole-109samples-LDpruned-maf0.05-snp-pvalues.assoc.filtered.logistic", header = FALSE, sep = "")
# head(plink_output)
colnames(plink_output) <- c("CHR", "SNP", "BP", "A1", "TEST", "NMISS", "OR", "STAT", "P") 

# 0.8% of NAs - no variation at those loci
summary(plink_output$P)
summary(plink_output$P)[7]/nrow(plink_output) * 100

# remove those loci with NA for a remaining 670660 SNPs
clean_snp_in_long_seq <- plink_output[!is.na(plink_output$P), ]
nrow(clean_snp_in_long_seq) #286117
ggplot(data = clean_snp_in_long_seq, aes(clean_snp_in_long_seq$P)) + geom_histogram(binwidth = 0.03) + ggtitle("Raw p-values from 286,117 SNPs") + xlab("unadjusted pvalues")

# http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
# I struggle with the interpretation of my pvalues
# the distribution is conservative - is something wrong with my test?
# the plink output is not automatically adjusted, I checked the manual
# we expect the results of a high-throughput experiment to resemble 
# a combination of a uniform distribution (from the null hypotheses) and a
# distribution with an overabundance of low p-values (from the non-null hypotheses).

# maybe check for quality control
# to test for departures from uniformity anywhere between 0 and 1, not necessarily only among low p-values.
# With a binwidth of 0.05, this amounts to checking 20 bins,
# and therefore using a corrected significance threshold of 0.05/20 = 0.0025, or equivalently, a frequency
# threshold of F0.9975(m, b). For the data from the study by Fischl et al. [3] in Figure 4, m = 23,332
# and b = 0.05, so the frequency threshold is 1261.
# Let b denote the bin width of the histogram
b <- 0.03
# m denote the number of hypotheses being tested
m <-  nrow(clean_snp_in_long_seq)
# Quality control threshold :
h <- qbinom(p = 1 - b * 0.05, size = m, prob = b)
# proportion of SNPs with pvalue of 1 0.003844581
length(clean_snp_in_long_seq$P[clean_snp_in_long_seq$P == 1]) / nrow(clean_snp_in_long_seq) * 100

ggplot(data = clean_snp_in_long_seq, aes(clean_snp_in_long_seq$P)) + geom_histogram(binwidth = 0.03) + geom_abline(aes(), intercept = h) + labs(title = "Raw p-values from whole data maf>0.05", subtitle = "quality threshold shows that the analysis power is low", x = "unadjusted pvalues") 

```

Conclusion
- Removing more SNPs with a 0.05 minor allele frequency removed the peak around 1
- It is possible that the analysis power is too low
- MinION-flye assembly-based variants seem to be less noisy 

# Correcting for multiple adjustments
After testing individually all 286,117 loci, we correct for multiple comparisons and retrieve loci with a p-value of less than 5%. We use a very conservative approach: the correction with false discovery rate by Benjamini and Hochberg method.

```{r, eval = TRUE, echo = FALSE}
# adjust the p-value using Benjamini and Hochberg method
pvalue_vec <- clean_snp_in_long_seq$P
names(pvalue_vec) <- clean_snp_in_long_seq$SNP
all_adjusted_pvalues <- p.adjust(pvalue_vec, method = "BH", n = length(pvalue_vec))
clean_snp_in_long_seq$adj_pvalue <- all_adjusted_pvalues

# None of the adjusted pvalues are lower than 0.05
summary(all_adjusted_pvalues)
```
None of the adjusted pvalues are lower than 0.05.

# Manhattan plot

```{r, eval = TRUE, echo = FALSE}
# vector names of all scaffolds
scaffold_names <- unique(as.character(clean_snp_in_long_seq$CHR))

# make a small data.frame of scaffold names and ids
scaffold_df <- as.data.frame(cbind(scaffold_names, c(1:length(scaffold_names))))
colnames(scaffold_df) <- c("scaf_names", "scaf_ids")

# create a new column for ids in the large dataframe
clean_snp_in_long_seq$scaf_ids <- scaffold_df$scaf_ids[match(clean_snp_in_long_seq$CHR, scaffold_df$scaf_names)]

# keep only the important columns
manhattan_df <- clean_snp_in_long_seq[, c("BP", "SNP", "adj_pvalue", "scaf_ids", "P")]
manhattan_df$BP <- as.numeric(manhattan_df$BP)
manhattan_df$P <- as.numeric(manhattan_df$P)
manhattan_df$adj_pvalue <- as.numeric(manhattan_df$adj_pvalue)
manhattan_df$scaf_ids <- as.numeric(as.character(manhattan_df$scaf_ids))

# Plot figure in file
#pdf(file = "manhattan_df_unadjusted.pdf")
manhattan(manhattan_df, chr = "scaf_ids", bp = "BP", p = "adj_pvalue", snp = "SNP", suggestiveline = -log10(0.05), main = "286,117 adjusted SNPs in linkage equilibrium in 3 Pheidole populations")
manhattan(manhattan_df, chr = "scaf_ids", bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05), main = "286,117 SNPs in linkage equilibrium in 3 Pheidole populations")
#dev.off()

```

# Checking number of significant SNPs vs all SNPs 
A potential social chromosome would signal a high proportion of significant SNPs over all SNPs in a small number of contigs

```{r, eval = TRUE, echo = FALSE}
# change to numeric
clean_snp_in_long_seq$scaf_ids <- as.numeric(as.character(clean_snp_in_long_seq$scaf_ids))

# highest scaffold id
highest_scaffold_id <- clean_snp_in_long_seq$scaf_ids[which.max(clean_snp_in_long_seq$scaf_ids)]

# summary table
summary_table <- matrix(NA, nrow = highest_scaffold_id, ncol = 4)
colnames(summary_table) <- c("scaff_name", "total_SNP_num", "sig_SNP_num", "ratio")

# this will probably be a loop
for(i in 1:highest_scaffold_id){
    # subset dataframe
    snps_in_contig <- clean_snp_in_long_seq[clean_snp_in_long_seq$scaf_ids == i, ]
    # scaffold name
    scaffold_name <- unique(as.character(snps_in_contig$CHR))
    # number of total SNPs in 1 contig
    total_snp_num <- nrow(snps_in_contig)
    # number of significant SNPs (non-adjusted P-values)
    sig_snp_num <- nrow(subset(snps_in_contig, snps_in_contig$P <= 0.05))
    # ratio significant SNPs (non-adjusted P-values) / total SNPs
    sig_snp_ratio <- sig_snp_num / total_snp_num
    # save it as a row in the table
    summary_table[i, ] <- c(scaffold_name, total_snp_num, sig_snp_num, sig_snp_ratio)
}
# transform to dataframe
summary_table <- as.data.frame(summary_table)
# transform to numeric
summary_table$ratio <- as.numeric(as.character(summary_table$ratio))
# highest ratio at top of df
ordered_summary_table <- summary_table[order(-summary_table$ratio), ]
# save this table
write.table(ordered_summary_table, file = "result/ordered_summary_table",
      quote = FALSE, row.names = FALSE)
# plot the spread
ggplot(data = ordered_summary_table, aes(ordered_summary_table$ratio)) + 
  geom_histogram(binwidth = 0.01) +
  labs(title = "Proportion of Significant SNPs per contig", subtitle = "whole MinION assembly, unadjusted p-values", x = "sig SNP / all SNP (per contig)") 

# look at 719 contigs that have a ratio higher than 3rd quartile
interesting_contigs_table <- ordered_summary_table[ordered_summary_table$ratio > summary(ordered_summary_table$ratio)[5], ] 
nrow(interesting_contigs_table)

```
# Conclusion
There are 719 contigs that have a high ratio of significant SNPs/all SNPs (to be checked when non-coding regions are removed and when annotation happens)
