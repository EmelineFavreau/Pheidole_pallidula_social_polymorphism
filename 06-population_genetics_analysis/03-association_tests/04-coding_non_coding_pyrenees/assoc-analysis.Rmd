---
title: "Association analysis Italy (LD SNPs pruned)"
author: "EmelineFavreau"
date: "4 April 2019"
output:
  pdf_document: default
---

I tested each SNP for association with social type using logistic regression test implemented in plink, with PC1 and PC2 for covariates (related to longitude and latitude).
24,328 biallelic SNPs, in linkage equilibrium, supported by at least 75% of samples, on coding-only regions, in Italy only.


```{r eval = TRUE, echo = FALSE, include = FALSE}
# import files
# import plink output
plink_output          <- read.csv(file = "result/2019-04-04-flye-italy-genic-LDpruned-maf0.05-snp-pvalues.assoc.logistic.filtered", header = FALSE, sep = "")
# import file with contig name and number of SNPs
snp_per_contig_df     <- read.table(file = "2019-04-04-flye-italy-genic-snp-per-contig.txt", header = FALSE, sep = "")
# import file with contig name and length
contig_length_df      <- read.table(file = "intersected.contig.length", header = FALSE, sep = "")
# import output from Fisher
plink_output_fisher   <- read.csv(file = "result/2019-04-04-flye-italy-genic.assoc.fisher", header = TRUE, sep = "")
# import SNP matrix
snp_matrix            <- read.csv(file = "tmp/2019-04-04-flye-italy-genic-pruned-snp_matrix.txt", header = FALSE, sep = "\t")
# import sample list
sample_list_vec       <- read.table(file = "result/2019-04-04-flye-italy-genic-sample_list", header = FALSE, sep = "")
# import list of signifcant SNPs in Bruniquel
bruniquel_sig_snp_vec <- read.table(file = "../2019-04-03-coding-only-bruniquel-maf10percent/bruniquel_sig_snp", header = TRUE, sep = "")

# get libraries
basic_libraries <- c("qqman", "ggplot2")
for (lib in basic_libraries) {
        if (require(package = lib, character.only = TRUE)) {
                print("Successful")
        } else {
                print("Installing")
                install.packages(lib)
                library(lib, character.only = TRUE )
        }
}
```

# Regression analysis

## Evaluating raw p-value distribution (regression analysis)

```{r, eval = TRUE, echo = FALSE}
# name columns
colnames(plink_output) <- c("CHR", "SNP", "BP", "A1", "TEST", "NMISS", "OR", "STAT", "P") 

# 25% of NAs - no variation at those loci
# maybe those come from multicollinearity (regional SNPs that behave exactly like the covariates PC1 and PC2)
# summary(plink_output$P)
# sum(is.na(plink_output$P))/nrow(plink_output) * 100
no_variation_loci <- subset(plink_output, subset = !is.na(plink_output$P), select = SNP)

# remove those loci with NA for a remaining 18095 SNPs
plink_output_noNA <- subset(x = plink_output, subset = !is.na(plink_output$P))
# nrow(plink_output_noNA)
# 18095
# http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
# I struggle with the interpretation of my pvalues
# the distribution is conservative - is something wrong with my test?
# the plink output is not automatically adjusted, I checked the manual
# we expect the results of a high-throughput experiment to resemble 
# a combination of a uniform distribution (from the null hypotheses) and a
# distribution with an overabundance of low p-values (from the non-null hypotheses).

# maybe check for quality control
# to test for departures from uniformity anywhere between 0 and 1, not necessarily only among low p-values.
# With a binwidth of 0.05, this amounts to checking 20 bins,
# and therefore using a corrected significance threshold of 0.05/20 = 0.0025, or equivalently, a frequency
# threshold of F0.9975(m, b). For the data from the study by Fischl et al. [3] in Figure 4, m = 23,332
# and b = 0.05, so the frequency threshold is 1261.
# Let b denote the bin width of the histogram
b <- 0.03
# m denote the number of hypotheses being tested
m <-  nrow(plink_output_noNA)
# Quality control threshold :
h <- qbinom(p = 1 - b * 0.05, size = m, prob = b)

# Plot quality control threshold
snp_hist_title <- paste("Raw p-values from Italy coding-only data maf>0.05")
snp_hist_subtitle <- paste("QC: NO departures from uniformity found above the line")
ggplot(data = plink_output_noNA, aes(plink_output_noNA$P)) +
  geom_histogram(binwidth = 0.03) +
  geom_abline(aes(), intercept = h) +
  labs(title = snp_hist_title, subtitle = snp_hist_subtitle, x = "unadjusted pvalues") +
  theme_classic()

```

This plot shows that the sample size is too small to see anything interesting!


## Correcting for multiple adjustments (regression analysis)
After testing individually all 18.095 loci, we correct for multiple comparisons and retrieve loci with a p-value of less than 5%. 
We use a very conservative approach: the correction with false discovery rate by Benjamini and Hochberg method.

```{r, eval = TRUE, echo = FALSE}
# adjust the p-value using Benjamini and Hochberg method (ie FDR)
# values are ordered the same way as the input
plink_output_noNA$adj_pvalue <- p.adjust(plink_output_noNA$P, method = "BH")

# Are any adjusted pvalues lower than 0.05 ?
if(sum(plink_output_noNA$adj_pvalue <= 0.05) == 0){
  print("None of the adjusted pvalues are lower than 0.05")
} else {
  print(paste(sum(plink_output_noNA$adj_pvalue <= 0.05), "adjusted pvalues are lower than 0.05"))
}
# None of the adjusted pvalues are lower than 0.05
```



## Manhattan plots (regression analysis)

```{r, eval = TRUE, echo = FALSE}
# name columns in object containing SNP number per contig
colnames(snp_per_contig_df) <- c("SNP_num","contig_names")
# order by number of SNPs
snp_per_contig_df_ordered <- snp_per_contig_df[order(-snp_per_contig_df$SNP_num), ]
# change into dataframe
snp_per_contig_df_ordered <- as.data.frame(snp_per_contig_df_ordered)
# make a small dataframe of contig names and rank (by descending number of SNPs within a given contig)
contig_ordered_by_snp_num_df <- as.data.frame(cbind(as.character(snp_per_contig_df_ordered$contig_names), c(1:nrow(snp_per_contig_df_ordered))))
# name columns
colnames(contig_ordered_by_snp_num_df) <- c("contig_names", "contig_rank_by_snp_num")



# Prepare the data for length of contig
# name columns
colnames(contig_length_df) <- c("contig_names", "contig_length")
# change contig names from short to long form
contig_length_df$contig_names <- gsub(pattern = "Ppal_E.", x = contig_length_df$contig_names, replacement = "")
contig_length_df$contig_names <- gsub(pattern = "$", x = contig_length_df$contig_names, replacement = "_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
# order by number of SNPs
contig_length_df_ordered <- contig_length_df[order(-contig_length_df$contig_length), ]
# change into dataframe
contig_length_df_ordered <- as.data.frame(contig_length_df_ordered)
# make a small data.frame of contig names and rank (by descending contig length)
contig_ordered_by_length_df <- as.data.frame(cbind(as.character(contig_length_df_ordered$contig_names), c(1:nrow(contig_length_df_ordered))))
# name columns
colnames(contig_ordered_by_length_df) <- c("contig_names", "contig_rank_by_length")


# create 2 new columns for snp and length ranks in the large dataframe plink_output_noNA
plink_output_noNA$contig_rank_by_snp_num <- contig_ordered_by_snp_num_df$contig_rank_by_snp_num[match(plink_output_noNA$CHR, contig_ordered_by_snp_num_df$contig_names)]
plink_output_noNA$contig_rank_by_length <- contig_ordered_by_length_df$contig_rank_by_length[match(plink_output_noNA$CHR, contig_ordered_by_length_df$contig_names)]
# check result
# head(plink_output_noNA)

# manhattan function needs specific classes
plink_output_noNA$BP                     <- as.numeric(plink_output_noNA$BP)
plink_output_noNA$P                      <- as.numeric(plink_output_noNA$P)
plink_output_noNA$adj_pvalue             <- as.numeric(plink_output_noNA$adj_pvalue)
plink_output_noNA$contig_rank_by_snp_num <- as.numeric(as.character(plink_output_noNA$contig_rank_by_snp_num))
plink_output_noNA$contig_rank_by_length  <- as.numeric(as.character(plink_output_noNA$contig_rank_by_length))

# Plot figure by ordering contigs by total number of SNPs
# WARNING: DO IT ON THE CLUSTER, THESE COMMENTED COMMANDS TAKES AGES
#pdf(file = "manhattan_df_unadjusted.pdf")
#manhattan(manhattan_df, chr = "contig_ids", bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05), main = "54,262 SNPs in linkage equilibrium in 3 Pheidole populations", xlab = "contigs ordered by total number of SNPs")
#dev.off()

# Plot figure by ordering contigs by total length
#pdf(file = "2019-03-25-manhattan_df_by_length.pdf")
#manhattan(manhattan_df, chr = "contig_length_ids", bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05), main = "54,262 SNPs in linkage equilibrium in 3 Pheidole populations", xlab = "contigs ordered by length")
#dev.off()

# Plot manhattan plot for only the 10 longest contigs
plink_output_noNA_ten_longest_contigs <- subset(plink_output_noNA, plink_output_noNA$contig_rank_by_length %in% 1:10)
man_title <- paste("SNPs in Italy for 10 longest contigs")
man_xlab  <- paste("contigs ordered by length")
manhattan(plink_output_noNA_ten_longest_contigs, chr = "contig_rank_by_length",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          main = man_title, xlab = man_xlab)

# Plot manhattan plot for only the 20 longest contigs
plink_output_noNA_twenty_longest_contigs <- subset(plink_output_noNA, plink_output_noNA$contig_rank_by_length %in% 1:20)
man_title <- paste("SNPs in Italy for 20 longest contigs")
man_xlab  <- paste("contigs ordered by length")
manhattan(plink_output_noNA_twenty_longest_contigs, chr = "contig_rank_by_length",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          main = man_title, xlab = man_xlab)


# Plot manhattan plot for only the 10 contigs with the most SNPs
plink_output_noNA_ten_SNPrich_contigs <- subset(plink_output_noNA, plink_output_noNA$contig_rank_by_snp_num %in% 1:10)
man_title <- paste("SNPs in Italy for the 10 contigs with the most SNPs")
man_xlab  <- paste("contigs ordered by total SNP counts")
manhattan(plink_output_noNA_ten_SNPrich_contigs, chr = "contig_rank_by_snp_num",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          main = man_title, xlab = man_xlab)

# Plot manhattan plot for only the 20 contigs with the most SNPs
plink_output_noNA_twenty_SNPrich_contigs <- subset(plink_output_noNA, plink_output_noNA$contig_rank_by_snp_num %in% 1:20)
man_title <- paste("SNPs in Italy for the 20 contigs with the most SNPs")
man_xlab  <- paste("contigs ordered by total SNP counts")
manhattan(plink_output_noNA_twenty_SNPrich_contigs, chr = "contig_rank_by_snp_num",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          main = man_title, xlab = man_xlab)
```

## Conclusion from regression analysis:
- no significant SNP for association with social type
- twenty largest contigs do not show any abnormal peak in Manhattan plots
- Regression analysis estimates the relationship between a dependent variable (here, number of queens) and an independent variable (SNPs). Covariates were added to take geographical structure in consideration.
- The main issue is that the number of significant SNPs is probably small, and maximum likelihood estimation of the logistic model is suffer from small-sample bias (ie rare events are not detected).


Another way is to test for association is allele counting Fisher test, that describes relationships but does not adjust for possible confounding variables.

# Fisher test

```{r, eval = TRUE, echo = FALSE}
# variation at all loci
# summary(plink_output_fisher$P)

# nrow(plink_output_fisher) #24328
# ggplot(data = clean_snp_in_long_seq, aes(clean_snp_in_long_seq$P)) + 
#   geom_histogram(binwidth = 0.03) +
#   ggtitle("Fisher raw p-values from 54,259 SNPs") +
#   xlab("unadjusted pvalues")

# http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
# I struggle with the interpretation of my pvalues
# the distribution is conservative - is something wrong with my test?
# the plink output is not automatically adjusted, I checked the manual
# we expect the results of a high-throughput experiment to resemble 
# a combination of a uniform distribution (from the null hypotheses) and a
# distribution with an overabundance of low p-values (from the non-null hypotheses).

# maybe check for quality control
# to test for departures from uniformity anywhere between 0 and 1, not necessarily only among low p-values.
# With a binwidth of 0.05, this amounts to checking 20 bins,
# and therefore using a corrected significance threshold of 0.05/20 = 0.0025, or equivalently, a frequency
# threshold of F0.9975(m, b). For the data from the study by Fischl et al. [3] in Figure 4, m = 23,332
# and b = 0.05, so the frequency threshold is 1261.
# Let b denote the bin width of the histogram
# b <- 0.03
# # m denote the number of hypotheses being tested
# m <-  nrow(clean_snp_in_long_seq)
# # Quality control threshold :
# h <- qbinom(p = 1 - b * 0.05, size = m, prob = b)
# # proportion of SNPs with pvalue of 1 0.003880331
# # length(clean_snp_in_long_seq$P[clean_snp_in_long_seq$P == 1]) / nrow(clean_snp_in_long_seq) * 100
# 
# Plot quality control threshold
snp_hist_title <- paste("Fisher: Raw p-values from Italy coding-only data maf>0.05")
snp_hist_subtitle <- paste("QC: departures from uniformity found above the line")
ggplot(data = plink_output_fisher, aes(plink_output_fisher$P)) +
  geom_histogram(binwidth = 0.03) +
  geom_abline(aes(), intercept = h) +
  labs(title = snp_hist_title, subtitle = snp_hist_subtitle, x = "unadjusted pvalues") +
  theme_classic()

```

Using Fisher test (i.e. no population structure), the plink output includes many SNPs with p-values around 1.

## Fisher: Correcting for multiple adjustments
After testing individually all 24,328 loci, we correct for multiple comparisons and retrieve loci with a p-value of less than 5%. 
We use a very conservative approach: the correction with false discovery rate by Benjamini and Hochberg method.

```{r, eval = TRUE, echo = FALSE}
# adjust the p-value using Benjamini and Hochberg method (ie FDR)
# values are ordered the same way as the input
plink_output_fisher$adj_pvalue <- p.adjust(plink_output_fisher$P, method = "BH")

# Are any adjusted pvalues lower than 0.05 ?
if(sum(plink_output_fisher$adj_pvalue <= 0.05) == 0){
  print("None of the adjusted pvalues are lower than 0.05")
  plink_output_fisher_ordered <- plink_output_fisher[order(plink_output_fisher$P), ]
  # keep the top SNPs (lowest pvalues)
  sig_snp_fisher_output <- plink_output_fisher_ordered[1:10, ]
  sig_snp_vec <- as.character(sig_snp_fisher_output$SNP)
  sig_snp_fisher_output$CHR <- as.character(sig_snp_fisher_output$CHR)
  write.table(x = sig_snp_vec, file = "italy_top_snp", quote = FALSE)
} else {
  print(paste(sum(plink_output_fisher$adj_pvalue <= 0.05), "adjusted pvalues are lower than 0.05"))
  sig_snp_fisher_output    <- subset(plink_output_fisher, subset = plink_output_fisher$adj_pvalue <= 0.05)
  sig_snp_vec <- as.character(sig_snp_fisher_output$SNP)
}
# None of the adjusted pvalues are lower than 0.05
```


## Fisher: Manhattan plots

```{r, eval = TRUE, echo = FALSE}
# create 2 new columns for snp and length ranks in the large dataframe plink_output_fisher
plink_output_fisher$contig_rank_by_snp_num <- contig_ordered_by_snp_num_df$contig_rank_by_snp_num[match(plink_output_fisher$CHR, contig_ordered_by_snp_num_df$contig_names)]
plink_output_fisher$contig_rank_by_length <- contig_ordered_by_length_df$contig_rank_by_length[match(plink_output_fisher$CHR, contig_ordered_by_length_df$contig_names)]
# check result
# head(plink_output_fisher)

# info just about the significant SNPs and their contigs
sig_contig_fisher_output <- subset(plink_output_fisher, subset = plink_output_fisher$CHR %in% sig_snp_fisher_output$CHR)

# manhattan function needs specific classes
plink_output_fisher$BP                     <- as.numeric(plink_output_fisher$BP)
plink_output_fisher$P                      <- as.numeric(plink_output_fisher$P)
plink_output_fisher$adj_pvalue             <- as.numeric(plink_output_fisher$adj_pvalue)
plink_output_fisher$contig_rank_by_snp_num <- as.numeric(as.character(plink_output_fisher$contig_rank_by_snp_num))
plink_output_fisher$contig_rank_by_length  <- as.numeric(as.character(plink_output_fisher$contig_rank_by_length))

# Plot whole manhattan
man_title <- paste("Fisher: all SNPs, in Italy")
man_xlab  <- paste("contigs ordered by length")
man_snp <- as.character(sig_snp_fisher_output$SNP)
bruni_snp <- "contig_1018_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon:705753C,T"
manhattan(plink_output_fisher, chr = "contig_rank_by_length",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          highlight = bruni_snp, main = man_title, xlab = man_xlab)


# Plot manhattan plot for only the 10 longest contigs
plink_output_fisher_ten_longest_contigs <- subset(plink_output_fisher, plink_output_fisher$contig_rank_by_length %in% 1:10)
man_title <- paste("Fisher: SNPs in Italy for 10 longest contigs")
man_xlab  <- paste("contigs ordered by length")
manhattan(plink_output_fisher_ten_longest_contigs, chr = "contig_rank_by_length",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          main = man_title, xlab = man_xlab)

# Plot manhattan plot for only the 10 longest contigs and the contigs with significant SNPs
plink_output_fisher_ten_longest_contigs_sig_snp <- rbind(sig_contig_fisher_output,
                                                         plink_output_fisher_ten_longest_contigs)
# change to numeric
plink_output_fisher_ten_longest_contigs_sig_snp$contig_rank_by_length <- as.numeric(as.character(plink_output_fisher_ten_longest_contigs_sig_snp$contig_rank_by_length))
man_title <- paste("Fisher: Top SNPs and 10 longest contigs in Italy")
man_xlab  <- paste("contigs ordered by length")
man_snp <- as.character(sig_snp_fisher_output$SNP)
manhattan(plink_output_fisher_ten_longest_contigs_sig_snp, chr = "contig_rank_by_length",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          highlight = man_snp, main = man_title, xlab = man_xlab)


# Plot manhattan plot for only the 10 contigs with the most SNPs
plink_output_fisher_ten_SNPrich_contigs <- subset(plink_output_fisher, plink_output_fisher$contig_rank_by_snp_num %in% 1:10)
plink_output_fisher_ten_SNPrich_contigs_sig_snp <- rbind(sig_contig_fisher_output,
                                                         plink_output_fisher_ten_SNPrich_contigs)
# change to numeric
plink_output_fisher_ten_SNPrich_contigs_sig_snp$contig_rank_by_snp_num <- as.numeric(as.character(plink_output_fisher_ten_SNPrich_contigs_sig_snp$contig_rank_by_snp_num))
man_title <- paste("Fisher: Top SNPs and 10 contigs with most SNPs in Italy")
man_xlab  <- paste("contigs ordered by total SNP counts")
manhattan(plink_output_fisher_ten_SNPrich_contigs_sig_snp, chr = "contig_rank_by_snp_num",
          bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05),
          highlight = man_snp, main = man_title, xlab = man_xlab)

```

With a Fisher test, no SNP is significant.



## What are those top 10 SNPs?
Homozygote for monogynous? Heterozygote for polygynous?
Same as in Bruniquel?

```{r, eval = TRUE, echo = FALSE}
# keep the snp ids in a vector
snp_id <- as.vector(snp_matrix[, 1])

# keep the position of the loci
loci_and_position_table <- snp_matrix[, 1:2]
colnames(loci_and_position_table ) <- c("SNPid", "position")

# remove first two rows (uninformative, snp id and location)
# head(snp_matrix)
snp_matrix1 <- snp_matrix[, 3:ncol(snp_matrix)]

# Turn the matrix on its side (rows = individuals, columns = loci)
snp_matrix1t <- t(snp_matrix1)

# change the sample names for biological names by sourcing the 46 colony names
colnames(sample_list_vec) <- "sample_name"
colony_names <- as.character(sample_list_vec$sample_name)

# change 4 sample names to the right genotype
colony_names <- gsub(pattern = "I27-N_I27-N", replacement = "I27-P_I27-P", x = colony_names)
colony_names <- gsub(pattern = "A56-N_A56-N", replacement = "A56-M_A56-M", x = colony_names)
colony_names <- gsub(pattern = "andrea-N_andrea-N", replacement = "andrea-P_andrea-P", x = colony_names)
colony_names <- gsub(pattern = "muna-N_muna-N", replacement = "muna-P_muna-P", x = colony_names)


# make the sample names in the matrix row biologically meaningful
row.names(snp_matrix1t) <- colony_names

# make the snp_id in the matrix column meaningful
colnames(snp_matrix1t) <- snp_id

# subset the colony names for each genotype
M <- as.character(colony_names[grep("M$", colony_names)])
M_sample_num <- length(M)
P <- as.character(colony_names[grep("P$", colony_names)])
P_sample_num <- length(P)
# reorder the rows by population - now number of individuals is 112
snp_matrix2 <- snp_matrix1t[c(M, P), ]
# check the different types of genotypes by uncommenting the following line
# unique(as.vector(unlist(snp_matrix2))) 
# "0/1" "0/0" "./." "1/1"
# 0: Reference
# 1: Alternate allele
# 2: Second alternate allele
# transform the matrix content so that genotypes are coded as alternative allele count
# example: in the vcf file 0|0 means that both alleles are reference 
# so I code this as 0 alternative alleles
snp_matrix2 <- as.matrix(snp_matrix2)
snp_matrix2[snp_matrix2 == "0/0"] <- 0 
snp_matrix2[snp_matrix2 == "0/1"] <- 1
snp_matrix2[snp_matrix2 == "./."] <- NA
snp_matrix2[snp_matrix2 == "1/1"] <- 2

# sanity check: genotypes are changed into the wanted code (but character class)
# snp_matrix2[1:2, 1:2]
# change class of each genotype, from character to numeric
snp_matrix2df <- as.data.frame(apply(snp_matrix2, 2, as.numeric), row.names = rownames(snp_matrix2))

# obtain snp matrix just for the 10 significant SNPs
sig_snp_mat <- snp_matrix2df[, colnames(snp_matrix2df) %in% sig_snp_vec]

# for monogynous, proportion of heterozygotes? (coded 1)
mono_samples <- grep(pattern = "-M", x = rownames(sig_snp_mat), value = TRUE)
poly_samples <- grep(pattern = "-P", x = rownames(sig_snp_mat), value = TRUE)
het_prop_in_M_vec <- c()
het_prop_in_P_vec <- c()
for(position in 1:length(colnames(sig_snp_mat))){
  het_prop_in_M_vec <- c(het_prop_in_M_vec, 
                         length(which(sig_snp_mat[rownames(sig_snp_mat) %in% mono_samples, position] == 0)) / length(sig_snp_mat[rownames(sig_snp_mat) %in% mono_samples, position]))
  het_prop_in_P_vec <- c(het_prop_in_P_vec,
                         length(which(sig_snp_mat[rownames(sig_snp_mat) %in% poly_samples, position] == 0)) / length(sig_snp_mat[rownames(sig_snp_mat) %in% poly_samples, position]))
}
mydf <- cbind(c(colnames(sig_snp_mat), colnames(sig_snp_mat)),
              c(het_prop_in_M_vec, het_prop_in_P_vec),
              c( rep("M", times = length(het_prop_in_M_vec)) , rep("P", times = length(het_prop_in_P_vec))))
mydf <- as.data.frame(mydf)
colnames(mydf) <- c("snpID", "het_prop", "social_type")
mydf$het_prop <- as.numeric(as.character(mydf$het_prop))
mydf$snpID <- as.character(mydf$snpID)

# Plot heterozygosity proportion
snp_hist_title <- paste("Alleles associated with social type")
snp_hist_subtitle <- paste("For Top SNPs in Italy")
ggplot(data = mydf, aes(x = snpID, y = het_prop)) +
  geom_line(aes(colour = social_type, group = social_type)) +
  labs(title = snp_hist_title, subtitle = snp_hist_subtitle, 
       x = "loci", y = "Proportion of homozygosity with reference") +
  theme_classic()



# ok, what is the genome average?
# obtain snp matrix just for 1000 random SNPs
random_snp_vec <- sample(x = colnames(snp_matrix2df), size = 10)
# check they are not sig
while(sum(random_snp_vec %in% sig_snp_vec) > 0){
  random_snp_vec <- sample(x = colnames(snp_matrix2df), size = 10)
}

random_snp_mat <- snp_matrix2df[, colnames(snp_matrix2df) %in% random_snp_vec]
het_prop_in_M_vec <- c()
het_prop_in_P_vec <- c()
for(position in 1:length(colnames(random_snp_mat))){
  het_prop_in_M_vec <- c(het_prop_in_M_vec, 
                         length(which(random_snp_mat[rownames(random_snp_mat) %in% mono_samples, position] == 0)) / length(random_snp_mat[rownames(random_snp_mat) %in% mono_samples, position]))
  het_prop_in_P_vec <- c(het_prop_in_P_vec,
                         length(which(random_snp_mat[rownames(random_snp_mat) %in% poly_samples, position] == 0)) / length(random_snp_mat[rownames(random_snp_mat) %in% poly_samples, position]))
}
mydf <- cbind(c(colnames(random_snp_mat), colnames(random_snp_mat)),
              c(het_prop_in_M_vec, het_prop_in_P_vec),
              c( rep("M", times = length(het_prop_in_M_vec)) , rep("P", times = length(het_prop_in_P_vec))))
mydf <- as.data.frame(mydf)
colnames(mydf) <- c("snpID", "het_prop", "social_type")
mydf$het_prop <- as.numeric(as.character(mydf$het_prop))
mydf$snpID <- as.character(mydf$snpID)

# Plot heterozygosity proportion
snp_hist_title <- paste("Alleles NOT associated with social type")
snp_hist_subtitle <- paste("For 10 random SNPs in Italy")
ggplot(data = mydf, aes(x = snpID, y = het_prop)) +
  geom_line(aes(colour = social_type, group = social_type)) +
  labs(title = snp_hist_title, subtitle = snp_hist_subtitle, 
       x = "loci", y = "Proportion of homozygosity with reference") +
  theme_classic()


# are those SNPs the same as in Bruniquel?
if(sum(as.vector(bruniquel_sig_snp_vec$x) %in% colnames(sig_snp_mat)) > 0){
  print("There are common loci associated with social type in Bruniquel and Italy")
} else {
  print("There are no common loci associated with social type in Bruniquel and Italy")
}

```



# Conclusion
- Regression analysis does not isolate any significant SNP.
- Fisher analysis does not isolate any significant SNP.
- 

To do:

- Fisher test on Italy-only dataset


