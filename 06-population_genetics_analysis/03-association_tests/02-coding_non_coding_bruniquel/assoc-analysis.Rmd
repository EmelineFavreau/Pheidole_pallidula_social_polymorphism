---
title: "2019-02-05-pheidole-bruniquel-regression"
author: "EmelineFavreau"
date: "05 February 2019"
output:
  pdf_document: default
---

I tested each SNP for association with social type using logistic regression test implemented in plink, with PC1 and PC2 for covariates (related to longitude and latitude). 295,419 biallelic SNPs, in linkage equilibrium, supported by at least 75% of samples.


```{r eval = TRUE, echo = FALSE, include = FALSE}
# check the working directory
getwd() #"/Users/emeline/apocrita/2018-11-09-association_analysis_mixed_assembly/result/2019-01-03-association_analysis"
R.Version()$version.string # "R version 3.3.2 (2016-10-31)"
basic_libraries <- c("qqman", "ggplot2", "adegenet", "genetics", "pegas", "reshape2", "hierfstat")
for (lib in basic_libraries) {
        if (require(package = lib, character.only = TRUE)) {
                print("Successful")
        } else {
                print("Installing")
                install.packages(lib)
                library(lib, character.only = TRUE )
        }
}
```


# Evaluating raw p-value distribution

```{r, eval = TRUE, echo = FALSE}
plink_output <- read.csv("result/2019-03-14-bruniquel-LDpruned-maf0.05-snp-pvalues.assoc.filtered.logistic", header = FALSE, sep = "")
# head(plink_output)
colnames(plink_output) <- c("CHR", "SNP", "BP", "A1", "TEST", "NMISS", "OR", "STAT", "P") 

# 6% of NAs - no variation at those loci
summary(plink_output$P)
summary(plink_output$P)[7]/nrow(plink_output) * 100

# remove those loci with NA for a remaining 670660 SNPs
clean_snp_in_long_seq <- plink_output[!is.na(plink_output$P), ]
nrow(clean_snp_in_long_seq) #275819
ggplot(data = clean_snp_in_long_seq, aes(clean_snp_in_long_seq$P)) + geom_histogram(binwidth = 0.03) + ggtitle("Raw p-values from 275,819 SNPs") + xlab("unadjusted pvalues")

# http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
# I struggle with the interpretation of my pvalues
# the distribution is conservative - is something wrong with my test?
# the plink output is not automatically adjusted, I checked the manual
# we expect the results of a high-throughput experiment to resemble 
# a combination of a uniform distribution (from the null hypotheses) and a
# distribution with an overabundance of low p-values (from the non-null hypotheses).

# maybe check for quality control
# to test for departures from uniformity anywhere between 0 and 1, not necessarily only among low p-values.
# With a binwidth of 0.05, this amounts to checking 20 bins,
# and therefore using a corrected significance threshold of 0.05/20 = 0.0025, or equivalently, a frequency
# threshold of F0.9975(m, b). For the data from the study by Fischl et al. [3] in Figure 4, m = 23,332
# and b = 0.05, so the frequency threshold is 1261.
# Let b denote the bin width of the histogram
b <- 0.03
# m denote the number of hypotheses being tested
m <-  nrow(clean_snp_in_long_seq)
# Quality control threshold :
h <- qbinom(p = 1 - b * 0.05, size = m, prob = b)
# proportion of SNPs with pvalue of 1 0.006888575
length(clean_snp_in_long_seq$P[clean_snp_in_long_seq$P == 1]) / nrow(clean_snp_in_long_seq) * 100

ggplot(data = clean_snp_in_long_seq, aes(clean_snp_in_long_seq$P)) + geom_histogram(binwidth = 0.03) + geom_abline(aes(), intercept = h) + labs(title = "Raw p-values from Bruniquel data maf>0.05", subtitle = "quality threshold shows that the analysis power is low", x = "unadjusted pvalues") 

```

Conclusion
- Removing more SNPs with a 0.05 minor allele frequency removed the peak around 1
- It is possible that the analysis power is too low
- MinION-flye assembly-based variants seem to be less noisy 

# Correcting for multiple adjustments
After testing individually all 275,819 loci, we correct for multiple comparisons and retrieve loci with a p-value of less than 5%. We use a very conservative approach: the correction with false discovery rate by Benjamini and Hochberg method.

```{r, eval = TRUE, echo = FALSE}
# adjust the p-value using Benjamini and Hochberg method
pvalue_vec <- clean_snp_in_long_seq$P
names(pvalue_vec) <- clean_snp_in_long_seq$SNP
all_adjusted_pvalues <- p.adjust(pvalue_vec, method = "BH", n = length(pvalue_vec))
clean_snp_in_long_seq$adj_pvalue <- all_adjusted_pvalues

# None of the adjusted pvalues are lower than 0.05
summary(all_adjusted_pvalues)
```
None of the adjusted pvalues are lower than 0.05.

# Manhattan plot

```{r, eval = TRUE, echo = FALSE}
# vector names of all scaffolds
scaffold_names <- unique(as.character(clean_snp_in_long_seq$CHR))

# make a small data.frame of scaffold names and ids
scaffold_df <- as.data.frame(cbind(scaffold_names, c(1:length(scaffold_names))))
colnames(scaffold_df) <- c("scaf_names", "scaf_ids")

# create a new column for ids in the large dataframe
clean_snp_in_long_seq$scaf_ids <- scaffold_df$scaf_ids[match(clean_snp_in_long_seq$CHR, scaffold_df$scaf_names)]

# keep only the important columns
manhattan_df <- clean_snp_in_long_seq[, c("BP", "SNP", "adj_pvalue", "scaf_ids", "P")]
manhattan_df$BP <- as.numeric(manhattan_df$BP)
manhattan_df$P <- as.numeric(manhattan_df$P)
manhattan_df$adj_pvalue <- as.numeric(manhattan_df$adj_pvalue)
manhattan_df$scaf_ids <- as.numeric(as.character(manhattan_df$scaf_ids))

# Plot figure in file
#pdf(file = "manhattan_df_unadjusted.pdf")
manhattan(manhattan_df, chr = "scaf_ids", bp = "BP", p = "adj_pvalue", snp = "SNP", suggestiveline = -log10(0.05), main = "286,117 adjusted SNPs in linkage equilibrium in 3 Pheidole populations")
manhattan(manhattan_df, chr = "scaf_ids", bp = "BP", p = "P", snp = "SNP", suggestiveline = -log10(0.05), main = "286,117 SNPs in linkage equilibrium in 3 Pheidole populations")
#dev.off()

```


