---
title: "Do polygynous samples align as much as monogynous samples to the reference?"
author: "EmelineFavreau"
date: "12 June 2019"
output:
  html_document: default
  pdf_document: default
---

Using Bruniquel data for coding and non-coding regions, we ask whether each locus maps differently depending on the social type of the sample.
Here we compare the coverage of each base of the reference by social type.
There are 15 monogynous samples and 53 polygynous samples.

```{r setup, include = FALSE}
#knitr::opts_chunk$set(echo = TRUE, fig.width = 10, fig.height = 8)
```

```{r import all the data , eval = TRUE, echo = FALSE, include = FALSE}
# import coverage for monogynous - this takes few minutes
monogynous.coverage <- read.csv("result/monogynous-samples-bruniquel-codingnoncoding.read.depth",
                                header = FALSE,
                                sep = "",
                                stringsAsFactors = FALSE)

# import coverage for polygynous
polygynous.coverage <- read.csv("result/polygynous-samples-bruniquel-codingnoncoding.read.depth",
                                header = FALSE,
                                sep = "",
                                stringsAsFactors = FALSE)

# import M sample list
monogynous.sample.vec <- readLines("result/monogynous-samples-bruniquel-codingnoncoding.sample.list")

# import P sample list
polygynous.sample.vec <- readLines("result/polygynous-samples-bruniquel-codingnoncoding.sample.list")

# import snp mapping quality mean
snp_mapping_quality_mean_df <- read.csv("snp-mapping-quality-mean",
                                        header = FALSE,
                                        sep = "",
                                        stringsAsFactors = FALSE)

# import contig length
intersected_contig_length_df <- read.csv("../../../2019-03-06-minion_flye_QC/Ppal_E.contig.length",
                                         header = FALSE,
                                         sep = "",
                                         stringsAsFactors = FALSE)

# import snp matrix
snp_matrix  <- read.csv(file = "result/2019-03-14-bruniquel-snp_matrix.txt",
                        header = FALSE,
                        sep = "\t",
                        stringsAsFactors = FALSE)

# import sample list
sample_list_vec <- read.table(file = "result/2019-03-14-bruniquel-sample_names.txt",
                              header = FALSE,
                              stringsAsFactors = FALSE,
                              sep = "")

# import extreme and normal contig read depth mean by samples - outlier investigation
both_contig_coverage <- read.table(file = "result/both-contig-coverage",
                                   header = FALSE,
                                   sep = "\t")

both_contig_coverage_bymedian <- read.table(file = "result/both-contig-coverage-bymedian",
                                            header = FALSE,
                                            sep = "\t")

# import population info
pop_info_df <- read.csv(file = "S2_pheidole_pop_paper.csv")

# import mean read depth by 5kb regions of contig 1346
#contig_1346_5kb_coverage <- read.table(file = "result/contig_1346-all-samples-read-count5kb", header = TRUE, sep = "\t")

# import read depth for 3 contigs and 2 samples (read balance)
read_balance_query  <- read.csv(file = "result/2020-02-17-read-balance-query",
                        header = FALSE,
                        stringsAsFactors = FALSE,
                        sep = "\t")

# load all the libraries
# get libraries
basic_libraries <- c("qqman", "ggplot2", "gridExtra", "calibrate", "dplyr", "ggrepel", "tidyr", "colorspace")
for (lib in basic_libraries) {
        if (require(package = lib, character.only = TRUE)) {
                print("Successful")
        } else {
                print("Installing")
                install.packages(lib)
                library(lib, character.only = TRUE )
        }
}
```

# What we expect
The reference is monogynous. 
We expect the monogynous samples to map better to the reference, because of similarity.
We expect the polygynous samples to map well, but maybe not so well in complex regions.
These complex regions could signal something biologically interesting.

We look at how read depth varies between monogynous and polygynous, more specifically we perfom a ratio P / M and observe the fold change of P with respect to M.


```{r plot read depth for just two contigs, eval = TRUE, echo = FALSE, warning = FALSE, width = 20, height = 5}
# name columns
colnames(monogynous.coverage) <- c("chr", "loc", monogynous.sample.vec)
colnames(polygynous.coverage) <- c("chr", "loc", polygynous.sample.vec)

# select columns to change class from character to numeric
M_cols_to_change <- c(3:ncol(monogynous.coverage))
P_cols_to_change <- c(3:ncol(polygynous.coverage))

# change class
monogynous.coverage[M_cols_to_change] <- sapply(monogynous.coverage[M_cols_to_change], as.numeric)
polygynous.coverage[P_cols_to_change] <- sapply(polygynous.coverage[P_cols_to_change], as.numeric)

# change NA for 0
monogynous.coverage[is.na(monogynous.coverage)] <- 0
polygynous.coverage[is.na(polygynous.coverage)] <- 0

# add a column for the SNP_name
monogynous.coverage$SNP_name <- paste(monogynous.coverage$chr, monogynous.coverage$loc, sep = "_")
polygynous.coverage$SNP_name <- paste(polygynous.coverage$chr, polygynous.coverage$loc, sep = "_")

# populate new column with means of read depth for each locus
monogynous.coverage$read_depth_mean <- rowMeans(x = monogynous.coverage[M_cols_to_change])
polygynous.coverage$read_depth_mean <- rowMeans(x = polygynous.coverage[P_cols_to_change])

# add a column for median of read depth
monogynous.coverage$read_depth_median <- apply(monogynous.coverage[M_cols_to_change], 1, median) 
polygynous.coverage$read_depth_median <- apply(polygynous.coverage[P_cols_to_change], 1, median) 

# calculate the mean normalised by the median (mean/median)
monogynous.coverage$read_depth_mean_normalised <- monogynous.coverage$read_depth_mean / monogynous.coverage$read_depth_median
polygynous.coverage$read_depth_mean_normalised <- polygynous.coverage$read_depth_mean / polygynous.coverage$read_depth_median

# make a wide dataframe
bruniquel_coverage_wide <- merge(x = monogynous.coverage[, c("SNP_name", "read_depth_mean_normalised")], 
                                 y = polygynous.coverage[, c("SNP_name", "read_depth_mean_normalised")], 
                                 by = "SNP_name")
# give colnames
colnames(bruniquel_coverage_wide) <- c("SNP_name", "read_depth_mean_normalised.M", "read_depth_mean_normalised.P")

# add a column for log2(meanPnorm / meanNnorm)
bruniquel_coverage_wide$log_fold_change <- log2(bruniquel_coverage_wide$read_depth_mean_normalised.M / bruniquel_coverage_wide$read_depth_mean_normalised.P)

                        
# change name of SNP for the short version
bruniquel_coverage_wide$contig <- gsub(x = bruniquel_coverage_wide$SNP_name, pattern = "_pilon.*", replacement = "")  #yw was here


# make a plot of read depth between M and P
plot_title    <- paste("Figure 1: SNP-level fold change of read depth in P samples with respect to M")
plot_subtitle <- paste("Data: contig1 and contig2, Bruniquel coding-only, no LD pruning, maf > 0.05")
x_title       <- paste("Locus")
y_title       <- paste("Log2 fold change of read depth (P / M)")
ggplot(subset(bruniquel_coverage_wide, subset = contig %in% c('contig_1', 'contig_2')), aes(x = SNP_name, y = log_fold_change, group = 1)) +
   geom_line() +
   labs(title = plot_title, subtitle = plot_subtitle, x = x_title, y = y_title) +
   theme_classic() +
   theme(axis.text.x = element_blank())

```


Visualising 2 contigs only, read depth varies quite a lot.
Comparing this visualisation with the previous analysis (only coding regions), we observe larger fold change here.



When we looked just at the coding regions, Contig 5068 had 1.8x more reads in the monogynous samples.
When we looked just at the coding regions, Contig 1122 was long and had 1.8x more reads in the monogynous samples.
Is the signal still the same when we look at both coding and non-coding regions ?

```{r contig level investigation, eval = TRUE, echo = FALSE, warning = FALSE}

### prep the data for a shorter name of contigs
monogynous.coverage$contig <- gsub(x = monogynous.coverage$chr, pattern = "_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon", replacement = "")
polygynous.coverage$contig <- gsub(x = polygynous.coverage$chr, pattern = "_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon", replacement = "")



### Normalise each read count by sample median
# copy the dataframe to overwrite it with normalised mean
monogynous.coverage_normalised <- monogynous.coverage
polygynous.coverage_normalised <- polygynous.coverage

# loop through each M sample
for(this_sample in monogynous.sample.vec){
  # obtain the median of each sample
  this_sample_median <- median(unlist(monogynous.coverage[, this_sample]))
  # normalise each read count by median
  monogynous.coverage_normalised[this_sample] <- monogynous.coverage[, this_sample] / this_sample_median
}

# loop through each P sample
for(this_sample in polygynous.sample.vec){
  # obtain the median of each sample
  this_sample_median <- median(unlist(polygynous.coverage[, this_sample]))
  # normalise each read count by median
  polygynous.coverage_normalised[this_sample] <- polygynous.coverage[, this_sample] / this_sample_median
}



### calculate means per contig and per social group
# contig names in a vector
short_contig_vec <- unique(bruniquel_coverage_wide$contig)

# make a dataframe to keep the results
bruniquel_contig_coverage <- as.data.frame(matrix(NA, ncol = 3, nrow = length(short_contig_vec)))

# name columns
colnames(bruniquel_contig_coverage) <- c("contig", "M_mean", "P_mean")

# add names of contigs
bruniquel_contig_coverage$contig <- short_contig_vec

# loop through each contig
for(this_contig in short_contig_vec){
  # calculate the mean of read counts for monogynous samples
  bruniquel_contig_coverage$M_mean[bruniquel_contig_coverage$contig == this_contig]   <- mean(unlist(monogynous.coverage_normalised[monogynous.coverage_normalised$contig == this_contig, monogynous.sample.vec]))
  # calculate mean of read counts for polygynous samples
  bruniquel_contig_coverage$P_mean[bruniquel_contig_coverage$contig == this_contig]   <- mean(unlist(polygynous.coverage_normalised[polygynous.coverage_normalised$contig == this_contig, polygynous.sample.vec]))
}

# calculate log2 fold change (P/M), normalised by median
bruniquel_contig_coverage$read_log2_fold_change <- log2( bruniquel_contig_coverage$M_mean / bruniquel_contig_coverage$P_mean)



### plot and look at outliers
# at the contig level, pick the top 10 contigs with largest departure from genome-wide read depth (less P read depth)
top_10_contig_vec <- bruniquel_contig_coverage$contig[order(bruniquel_contig_coverage$read_log2_fold_change)][1:10]

# rank the contigs from lowest fold change to highest
bruniquel_contig_coverage_ordered <- bruniquel_contig_coverage[order(bruniquel_contig_coverage$read_log2_fold_change), ]

# add a column for rank
bruniquel_contig_coverage_ordered$contig_rank <- 1:nrow(bruniquel_contig_coverage_ordered)
  
# save this table for future use
write.table(x = bruniquel_contig_coverage_ordered, file = "result/bruniquel_contig_coverage_ordered", quote = FALSE, row.names = FALSE)

# plot the result
# make a plot of read proportion (P / M)
plot_title    <- "Figure 2: Contig-level fold change of read depth in P samples with respect to M"
plot_subtitle <- "Data are read depth mean per contig, median normalised"
x_title       <- "unordered coding and non-coding contigs, from Bruniquel, maf > 0.05"
y_title       <- "Log2 fold change of read depth (P / M)"
ggplot(bruniquel_contig_coverage, aes(x = contig, y = read_log2_fold_change)) +
   geom_point(alpha = 0.4, shape = 15) +
   labs(title = plot_title, subtitle = plot_subtitle, x = x_title, y = y_title) +
   theme_classic() +
   theme(axis.text.x = element_blank()) +
   geom_hline(yintercept = 0, colour = "cyan")
    
# prepare the plot for MS figure 3a
x_title       <- "Contig"
y_title       <- "Log2 fold change of read depth (P / M)"
ggplot(bruniquel_contig_coverage, aes(x = contig, y = read_log2_fold_change)) +
   geom_point(size = 0.5, aes(colour = read_log2_fold_change), shape = 15) +
   labs(x = x_title, y = y_title) +
   theme_classic() +
   geom_hline(yintercept = 0, color = "grey95", size = 0.25) +
   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank(),
           axis.text.x      = element_blank(),
           axis.ticks.x     = element_blank(),
           legend.position = "none") +
  scale_color_continuous_diverging(palette = "Blue-Yellow 3") +
  scale_x_discrete(expand = expand_scale(mult = c(0.01, 0.01), add = c(0.5, 0.5)))

# save for MS
ggsave(filename = "../figure3a_coverageplot.png", width = 4, height = 4, dpi = 600)

```

The result with coding and non-coding is different than with just the coding data:

- y axis is even larger
- different extreme contigs


I now look at extreme contigs: the most enriched in M reads, and the most enriched in P reads.

```{r contig level investigation for 3 contigs, eval = TRUE, echo = FALSE, warning = FALSE}

# start a result df
read_balance_df <- as.data.frame(cbind(c("M", "P"), 
                                 # contig most enriched in M reads: "contig_4557"
                                 c(bruniquel_contig_coverage$contig[which.max(bruniquel_contig_coverage$read_log2_fold_change)],
                                 # contig most enriched in P reads: "contig_3700"
                                   bruniquel_contig_coverage$contig[which.min(bruniquel_contig_coverage$read_log2_fold_change)]
                                  )),
                                 stringsAsFactors = FALSE)

# name columns
colnames(read_balance_df) <- c("social", "contig")
                                 

# name columns
colnames(intersected_contig_length_df) <- c("Ppal_E_contig", "bp")

# add short name for contigs
intersected_contig_length_df$contig <- gsub(x = intersected_contig_length_df$Ppal_E_contig,
                                            pattern = "Ppal_E.",
                                            replacement = "")
# add contig length
read_balance_df$contig_length <- intersected_contig_length_df$bp[match(read_balance_df$contig, intersected_contig_length_df$contig)]
bruniquel_contig_coverage$contig_length <- intersected_contig_length_df$bp[match(bruniquel_contig_coverage$contig, intersected_contig_length_df$contig)] 
  
# find a non-extreme contig of the same length (log fold change is closest to 0)
read_balance_df <- as.data.frame(rbind(read_balance_df,
                                       c("neutral", 
                                        bruniquel_contig_coverage$contig[which.min(abs(bruniquel_contig_coverage$read_log2_fold_change - 0))],
                                        bruniquel_contig_coverage$contig_length[which.min(abs(bruniquel_contig_coverage$read_log2_fold_change - 0))])),
                                  stringsAsFactors = FALSE)

# select the 2 samples that will be representative of Bruniquel
monogynous.coverage_for_read_balance_df <- monogynous.coverage[monogynous.coverage$contig %in% read_balance_df$contig, ]
polygynous.coverage_for_read_balance_df <- polygynous.coverage[polygynous.coverage$contig %in% read_balance_df$contig, ]

# which is the deepest coverage for each contig?
max(monogynous.coverage_for_read_balance_df$read_depth_mean[monogynous.coverage_for_read_balance_df$contig == read_balance_df$contig[1]])
max(monogynous.coverage_for_read_balance_df$read_depth_mean[monogynous.coverage_for_read_balance_df$contig == read_balance_df$contig[2]])
max(monogynous.coverage_for_read_balance_df$read_depth_mean[monogynous.coverage_for_read_balance_df$contig == read_balance_df$contig[3]])
max(polygynous.coverage_for_read_balance_df$read_depth_mean[polygynous.coverage_for_read_balance_df$contig == read_balance_df$contig[1]])
max(polygynous.coverage_for_read_balance_df$read_depth_mean[polygynous.coverage_for_read_balance_df$contig == read_balance_df$contig[2]])
max(polygynous.coverage_for_read_balance_df$read_depth_mean[polygynous.coverage_for_read_balance_df$contig == read_balance_df$contig[3]])

# which sample has the most coverage for those contigs?  "A57-M" "A09-P"
names(which.max(apply(monogynous.coverage_for_read_balance_df[M_cols_to_change], 2, max)))
names(which.max(apply(polygynous.coverage_for_read_balance_df[P_cols_to_change], 2, max)))


# name columns
colnames(snp_matrix) <- c("contig", "loc", sample_list_vec$V1)

# add contig info
snp_matrix$contig <- polygynous.coverage$contig

# subset for first contig
subset_contig_1 <- snp_matrix[snp_matrix$contig == read_balance_df$contig[1], ]


# calculate read balance: at any given site, number of reads containing alternative alleles / total number of reads
# if not 0/0, there is a alternative allele 
colnames(read_balance_query) <- c("contig", "loc", "GT_A57M", "DP_A57M", "GT_A09P", "DP_A09P") 

# give column names to the dataset
colnames(read_balance_query) <- c("contig", "loc", "GT_A57M", "DP_A57M", "GT_A09P", "DP_A09P") 

# explore data (up to 4 variants per locus)
# "."   "1/1" "2/2" "0/0" "0/1" "0/3" "3/3" "0/2" "1/2" "4/4" "1/3" "2/3"
#unique(read_balance_query$GT_A57M) 

# "0/0" "1/1" "."   "0/1" "2/2" "0/3" "0/2" "1/2" "3/3" "2/3" "1/3" "4/4"
#unique(read_balance_query$GT_A09P)

# DP change . for 0
read_balance_query$DP_A09P[read_balance_query$DP_A09P == "."] <- 0
read_balance_query$DP_A57M[read_balance_query$DP_A57M == "."] <- 0

# GT change . for NA
read_balance_query$GT_A09P[read_balance_query$GT_A09P == "."] <- NA
read_balance_query$GT_A57M[read_balance_query$GT_A57M == "."] <- NA

# GT change "0/0" for 0 non-reference allele
read_balance_query$GT_A09P[read_balance_query$GT_A09P == "0/0"] <- 0
read_balance_query$GT_A57M[read_balance_query$GT_A57M == "0/0"] <- 0

# GT change "0/1" or "0/2" or "0/3" == read containing non-reference allele
read_balance_query$GT_A09P[read_balance_query$GT_A09P %in% c("0/1", "0/2", "0/3", "1/1", "1/2", "1/3", "2/2", "2/3", "3/3", "4/4")] <- 1
read_balance_query$GT_A57M[read_balance_query$GT_A57M %in% c("0/1", "0/2", "0/3", "1/1", "1/2", "1/3", "2/2", "2/3", "3/3", "4/4")] <- 1

# change class
read_balance_query$GT_A57M <- as.numeric(read_balance_query$GT_A57M)
read_balance_query$GT_A09P <- as.numeric(read_balance_query$GT_A09P)
read_balance_query$DP_A57M <- as.numeric(read_balance_query$DP_A57M)
read_balance_query$DP_A09P <- as.numeric(read_balance_query$DP_A09P)

# calculate ratio: number of non-reference reads/total number of reads
read_balance_query$read_balance_A57M <- read_balance_query$GT_A57M/read_balance_query$DP_A57M
read_balance_query$read_balance_A09P <- read_balance_query$GT_A09P/read_balance_query$DP_A09P
  
# visualise in histogram: 
# x axis: read balance (0-1)
# y axis: count

# basic histogram for all contigs
# ggplot(read_balance_query, aes(x = read_balance_A57M)) + 
#   geom_histogram(binwidth = 0.005) +
#   ggtitle("Three contigs") +
#   theme_classic()
# 
# ggplot(read_balance_query, aes(x = read_balance_A09P)) + 
#   geom_histogram(binwidth = 0.005) +
#   ggtitle("Three contigs") +
#   theme_classic()




########################################
# subset to one contig
read_balance_query_contig_4557 <- subset(read_balance_query,
                                         subset = contig == "contig_4557_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon",
                                         select = c("contig", "loc", "read_balance_A57M", "read_balance_A09P"))

# change dataset to plot a stacked histogram
read_balance_query_contig_4557_long <- gather(read_balance_query_contig_4557, type, read_balance, read_balance_A57M:read_balance_A09P)
read_balance_query_contig_4557_long$type <- gsub(x = read_balance_query_contig_4557_long$type,
                                                 pattern = "read_balance_A[0-9]*",
                                                 replacement = "")  



# basic histogram for extreme contig (enriched in M)
# contig most enriched in M reads: "contig_4557"
# "contig_4557_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon" 
# read balance counts are by social type and stacked
ggplot(read_balance_query_contig_4557_long, aes(x = read_balance, fill = type)) + 
  geom_histogram(binwidth = 0.005) +
  ggtitle("Contig enriched in single-queen reads") +
  expand_limits(x = 1) +
  scale_fill_manual(values = c("yellow", "purple")) +
  theme_classic() +
  theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank())

# save for MS
ggsave(filename = "../figure3c_coverageplot.png", width = 8, height = 4, dpi = 600)






# subset to one contig
read_balance_query_contig_3700 <- subset(read_balance_query,
                                         subset = contig == "contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon",
                                         select = c("contig", "loc", "read_balance_A57M", "read_balance_A09P"))

# change dataset to plot a stacked histogram
read_balance_query_contig_3700_long <- gather(read_balance_query_contig_3700, type, read_balance, read_balance_A57M:read_balance_A09P)
read_balance_query_contig_3700_long$type <- gsub(x = read_balance_query_contig_3700_long$type,
                                                 pattern = "read_balance_A[0-9]*",
                                                 replacement = "")  



# basic histogram for extreme contig (enriched in P)
# contig most enriched in P reads: "contig_3700"
# "contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon" 
# read balance counts are by social type and stacked
ggplot(read_balance_query_contig_3700_long, aes(x = read_balance, fill = type)) + 
  geom_histogram(binwidth = 0.005) +
  ggtitle("Contig enriched in mulitple-queen reads") +
  expand_limits(x = 1) +
  scale_fill_manual(values = c("yellow", "purple")) +
  theme_classic() +
  theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank())

# save for MS
ggsave(filename = "../figure3d_coverageplot.png", width = 8, height = 4, dpi = 600)






# subset to one contig
read_balance_query_contig_1470 <- subset(read_balance_query,
                                         subset = contig == "contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon",
                                         select = c("contig", "loc", "read_balance_A57M", "read_balance_A09P"))

# change dataset to plot a stacked histogram
read_balance_query_contig_1470_long <- gather(read_balance_query_contig_1470, type, read_balance, read_balance_A57M:read_balance_A09P)
read_balance_query_contig_1470_long$type <- gsub(x = read_balance_query_contig_1470_long$type,
                                                 pattern = "read_balance_A[0-9]*",
                                                 replacement = "")  



# basic histogram for extreme contig (enriched in P)
# contig most enriched in P reads: "contig_1470"
# "contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon" 
# read balance counts are by social type and stacked
ggplot(read_balance_query_contig_1470_long, aes(x = read_balance, fill = type)) + 
  geom_histogram(binwidth = 0.005) +
  ggtitle("Neutral") +
  expand_limits(x = 1) +
  scale_fill_manual(values = c("yellow", "purple")) +
  theme_classic() +
  scale_y_continuous(trans = 'log2') +
  theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank())


# save for MS
ggsave(filename = "../figure3e_coverageplot.png", width = 8, height = 4, dpi = 600)

# ggplot(subset(read_balance_query, subset = contig == "contig_4557_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"), aes(x = read_balance_A09P)) + 
#   geom_histogram(binwidth = 0.005, fill = 'yellow') +
#   ggtitle("Contig enriched in single-queen reads") +
#   expand_limits(x = 1) +
#   theme_classic() +
#   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
#            panel.grid.major = element_blank(),
#            panel.grid.minor = element_blank())

# save for MS

# # basic histogram for extreme contig (enriched in P)
# # contig most enriched in P reads: "contig_3700"
# # "contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"
# ggplot(subset(read_balance_query, subset = contig == "contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"), aes(x = read_balance_A57M)) + 
#   geom_histogram(binwidth = 0.005, fill = 'purple') +
#   ggtitle("Contig enriched in multiple-queen reads") +
#   expand_limits(x = 1) +
#   theme_classic() +
#   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
#            panel.grid.major = element_blank(),
#            panel.grid.minor = element_blank())

# ggplot(subset(read_balance_query, subset = contig == "contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"), aes(x = read_balance_A09P)) + 
#   geom_histogram(binwidth = 0.005, fill = 'purple') +
#   ggtitle("Contig enriched in multiple-queen reads") +
#   expand_limits(x = 1) +
#   theme_classic() +
#   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
#            panel.grid.major = element_blank(),
#            panel.grid.minor = element_blank())

# save for MS
# ggsave(filename = "../figure3f_coverageplot.png", width = 4, height = 4, dpi = 600)

# basic histogram for normal contig (not enriched in either social type)
# "contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"
# ggplot(subset(read_balance_query, subset = contig == "contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"), aes(x = read_balance_A57M)) + 
#   geom_histogram(binwidth = 0.005, fill = 'white') +
#   ggtitle("Neutral contig") +
#   scale_y_continuous(trans = 'log2') +
#   expand_limits(x = 1) +
#   theme_classic() +
#   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
#            panel.grid.major = element_blank(),
#            panel.grid.minor = element_blank())
# 
# # save for MS
# ggsave(filename = "../figure3g_coverageplot.png", width = 4, height = 4, dpi = 600)
# 
# ggplot(subset(read_balance_query, subset = contig == "contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon"), aes(x = read_balance_A09P)) + 
#   geom_histogram(binwidth = 0.005, fill = 'white') +
#   ggtitle("Neutral contig") +
#   scale_y_continuous(trans = 'log2') +
#   expand_limits(x = 1) +
#   theme_classic() +
#   theme(panel.background = element_rect(fill = "grey48", colour = "black", size = 0.5, linetype = "solid"),
#            panel.grid.major = element_blank(),
#            panel.grid.minor = element_blank())
# 
# # save for MS
# ggsave(filename = "../figure3h_coverageplot.png", width = 4, height = 4, dpi = 600)


```

A read balance of 1 means that all reads contained non-reference alleles at any given locus.

Here we take the 10 contigs with the strongest departure from genome-wide signal.
These ten are very small (5kb or less). So I removed the shortest contigs (less than 10kb) and then replotted the log2 fold change.

```{r investigation of extreme read depth, eval = TRUE, echo = FALSE, warning = FALSE}
### Step 1: length of contig
# name columns
colnames(intersected_contig_length_df) <- c("Ppal_E.contig.name", "length")
# change name of contig
intersected_contig_length_df$short_contig_name <- gsub(x = intersected_contig_length_df$Ppal_E.contig.name, pattern = "Ppal\\_E\\.", replacement = "")

# add the info to our df
bruniquel_contig_coverage$length <- intersected_contig_length_df$length[match(bruniquel_contig_coverage$contig, intersected_contig_length_df$short_contig_name)]

# remove contigs shorter than 10kb
bruniquel_contig_coverage_10kb <- subset(bruniquel_contig_coverage, subset = length > 10000)

# pick out the top ten contigs 
top_10_contig_vec_10kb <- bruniquel_contig_coverage_10kb$contig[order(bruniquel_contig_coverage_10kb$read_log2_fold_change)][1:10]

# plot the result
# make a plot of read proportion (P / M)
plot_title    <- "Figure 3: Contig-level fold change of read depth in P samples with respect to M"
plot_subtitle <- "Data are read depth mean per contig, normalised by median"
x_title       <- "unordered coding and non-coding contigs, from Bruniquel, maf > 0.05, longer than 10kb"
y_title       <- "Log2 fold change of read depth (P / M)"
ggplot(bruniquel_contig_coverage_10kb, aes(x = contig, y = read_log2_fold_change)) +
   geom_point(alpha = 0.4) +
   labs(title = plot_title, subtitle = plot_subtitle, x = x_title, y = y_title) +
   theme_classic() +
   theme(axis.text.x = element_blank()) +
   geom_hline(yintercept = 0, colour = "cyan")

# top 5 contigs with more M than P (south)
contig_M_enriched <- bruniquel_contig_coverage_10kb$contig[order(bruniquel_contig_coverage_10kb$read_log2_fold_change)][1:5]

# size of contig
contig_M_enriched_size <- bruniquel_contig_coverage_10kb$length[bruniquel_contig_coverage_10kb$contig %in% contig_M_enriched]

# top 5 contigs with more P than M (north)
contig_P_enriched <- bruniquel_contig_coverage_10kb$contig[order(-bruniquel_contig_coverage_10kb$read_log2_fold_change)][1:5]

# size of contig
contig_M_enriched_size <- bruniquel_contig_coverage_10kb$length[bruniquel_contig_coverage_10kb$contig %in% contig_P_enriched]


# 5 contigs with equal amount of reads (center) and similar size (less than 94528)
contig_not_enriched <- bruniquel_contig_coverage_10kb[bruniquel_contig_coverage_10kb$read_log2_fold_change < 0.00025 & bruniquel_contig_coverage_10kb$read_log2_fold_change > -0.00025 & bruniquel_contig_coverage_10kb$length < 94528, ]

# size of contig
contig_not_enriched_size <- bruniquel_contig_coverage_10kb$length[bruniquel_contig_coverage_10kb$contig %in% contig_not_enriched]

# obtain length of contig for those contigs
intersected_contig_length_df_extreme_contigs <- subset(intersected_contig_length_df, subset = short_contig_name %in% c(contig_M_enriched, contig_P_enriched, contig_not_enriched))

# vector of contig to create bed file for
contig_for_bed_file_vec <- c(contig_M_enriched, contig_P_enriched, contig_not_enriched)

for(position in 1:length(contig_for_bed_file_vec)){
  # make a bed file for each contig, 5kb window
  # second column is start (0-base) 
  second_column <- seq(from = 0, to = intersected_contig_length_df_extreme_contigs$length[intersected_contig_length_df_extreme_contigs$short_contig_name == contig_for_bed_file_vec[position]], by = 5000)
  
  # third column is end (1-base)
  third_column <- c(seq(from = 5000, to = intersected_contig_length_df_extreme_contigs$length[intersected_contig_length_df_extreme_contigs$short_contig_name == contig_for_bed_file_vec[position]], by = 5000), intersected_contig_length_df_extreme_contigs$length[intersected_contig_length_df_extreme_contigs$short_contig_name == contig_for_bed_file_vec[position]])
  
  # assemble the bed file
  bed_file <- cbind(second_column, third_column)
  
  # update name of contig
  contig_name_updated <- paste(contig_for_bed_file_vec[position], "_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon", sep = "")
  
  # add the name of contig
  bed_file <- cbind(rep(contig_name_updated, length(second_column)),
                    second_column,
                    third_column)
  
 
  # give name to bed file
  bed_file_name <- paste(contig_for_bed_file_vec[position], "5kb.BED", sep = "_")
  
  
  # save in current directory
  write.table(x = bed_file, file = bed_file_name, row.names = FALSE, col.names = FALSE, quote = FALSE, sep = "\t")
}
```

Here each point is a contig longer than 10kb.
Most of the contigs have a log2 fold change around 0.
Some contigs have extreme log2 fold change, be it trending toward polygynous (top of graph) and toward monogynous (bottom of graph).
It is quite balanced between each side of the graph.

```{r make a df of interesting contigs, eval = FALSE, echo = FALSE, warning = FALSE}
# add contig length to the main dataframe
# make a dataframe to gather the info about the contigs
top_10_contig_info_df <- subset(bruniquel_contig_coverage, subset = contig %in% top_10_contig_vec)
top_10_contig_info_df_10kb <- subset(bruniquel_contig_coverage_10kb, subset = contig %in% top_10_contig_vec_10kb)

### Step 1: check the mapping quality
# name columns
colnames(snp_mapping_quality_mean_df) <- c("SNP_name", "mean_mapping_quality")

# change name of SNP for the short version
snp_mapping_quality_mean_df$contig <- gsub(x = snp_mapping_quality_mean_df$SNP_name, pattern = "_pilon.*", replacement = "") 

# vector to add mapping quality mean
top_contig_mapping_qual_mean_vec <- c()
top_contig_mapping_qual_mean_vec_10kb <- c()

# mean mapping quality for the top 10 contigs (all lengths)
for(top_contig in top_10_contig_vec){
  top_contig_mapping_qual_mean_vec <- c(top_contig_mapping_qual_mean_vec, mean(snp_mapping_quality_mean_df$mean_mapping_quality[snp_mapping_quality_mean_df$contig == top_contig]))
}

# mean mapping quality for the top 10 contigs (above 10kb)
for(top_contig in top_10_contig_vec_10kb){
  top_contig_mapping_qual_mean_vec_10kb <- c(top_contig_mapping_qual_mean_vec_10kb, mean(snp_mapping_quality_mean_df$mean_mapping_quality[snp_mapping_quality_mean_df$contig == top_contig]))
}

# check the general trend for mapping quality
summary(snp_mapping_quality_mean_df$mean_mapping_quality)
summary(top_contig_mapping_qual_mean_vec) # lower range of mapping quality
summary(top_contig_mapping_qual_mean_vec_10kb) # higher range of mapping quality


# add the info to our df
top_10_contig_info_df$mapping_quality <- top_contig_mapping_qual_mean_vec
top_10_contig_info_df_10kb$mapping_quality <- top_contig_mapping_qual_mean_vec_10kb 

### Step 2: 
# check for length of contigs
# name columns
colnames(intersected_contig_length_df) <- c("Ppal_E.contig.name", "length")
# change name of contig
intersected_contig_length_df$short_contig_name <- gsub(x = intersected_contig_length_df$Ppal_E.contig.name, pattern = "Ppal\\_E\\.", replacement = "")
# add the info to our df
top_10_contig_info_df$length <- intersected_contig_length_df$length[match(top_10_contig_info_df$contig, intersected_contig_length_df$short_contig_name)]
top_10_contig_info_df_10kb$length <- intersected_contig_length_df$length[match(top_10_contig_info_df_10kb$contig, intersected_contig_length_df$short_contig_name)]
  
print(top_10_contig_info_df)
print(top_10_contig_info_df_10kb)


```


I took two contigs from this dataset: the extreme contig with the lowest log2 value (contig_1346) and a "normal" contig with very little difference between monogynous and polygynous samples (contig_1470).
I used bedtools to obtain the read depth for each sample in the alignment files, in an effort to pick out potential outlier samples that pulls down the log2 value.
My expectations: in the extreme contig, one or few samples have an abnormal read depth at this contig, but not in the normal contig.

```{r check sample-based read depth for both contigs, eval = FALSE, echo = FALSE, warning = FALSE}
# name columns
colnames(both_contig_coverage) <- c("sample_names", "extreme_contig", "extreme_contig_coverage", "normal_contig", "normal_contig_coverage")

# clean sample names
both_contig_coverage$sample_names_cleaned <- gsub(x = both_contig_coverage$sample_names, pattern = "coverage\\-|\\-interesting\\-contigs", replacement = "")

# remove samples not from Bruniquel
both_contig_coverage_bruniquel <- subset(both_contig_coverage, subset = sample_names_cleaned %in% c(monogynous.sample.vec, polygynous.sample.vec))

# change from wide to long format
both_contig_coverage_long <- subset(both_contig_coverage_bruniquel, select = c("sample_names_cleaned", "extreme_contig_coverage", "normal_contig_coverage"))

# add a social column
both_contig_coverage_long$social <- gsub(x = both_contig_coverage_long$sample_names_cleaned, pattern = ".*\\-", replacement = "")

# make it factor for the plotting
both_contig_coverage_long$social <- factor(both_contig_coverage_long$social, levels = both_contig_coverage_long$social[order(both_contig_coverage_long$social)])

both_contig_coverage_long$sample_names_cleaned <- factor(both_contig_coverage_long$sample_names_cleaned, levels = both_contig_coverage_long$sample_names_cleaned[order(both_contig_coverage_long$social)])

# test if distributions of each social type are continuous (null hypothesis) or different in location and shape
ks.test(x = both_contig_coverage_long$extreme_contig_coverage, y = both_contig_coverage_long$normal_contig_coverage)$p.value
wilcox.test(x = both_contig_coverage_long$extreme_contig_coverage, y = both_contig_coverage_long$normal_contig_coverage)$p.value

# keep a list to make plot
make_plot <- list()

# plot a barplot: x axis are samples, y axis are read count
plot_title    <- "Extreme contig"
x_title       <- "samples"
y_title       <- "Read depth mean"
make_plot[[1]] <- ggplot(both_contig_coverage_long, aes(x = sample_names_cleaned, y = extreme_contig_coverage, fill = social)) +
   geom_bar(stat = "identity") +
   labs(title = plot_title, x = x_title, y = y_title) +
   theme_classic() + 
   # Monogynous orange f, Polygynous purple 9
   scale_fill_manual(values   = c("#f1a340", "#998ec3")) + 
   theme(axis.text.x  = element_text(angle = 45, vjust = 0.5, size = 4.5)) +
   scale_y_continuous(limits = c(0, 20))

# plot a barplot: x axis are samples, y axis are read count
plot_title    <- "Normal contig"
x_title       <- "samples"
y_title       <- "Read depth mean"
make_plot[[2]] <- ggplot(both_contig_coverage_long, aes(x = sample_names_cleaned, y = normal_contig_coverage, fill = social)) +
   geom_bar(stat = "identity") +
   labs(title = plot_title, x = x_title, y = y_title) +
   theme_classic() + 
   # Monogynous orange f, Polygynous purple 9
   scale_fill_manual(values   = c("#f1a340", "#998ec3")) + 
   theme(axis.text.x  = element_text(angle = 45, vjust = 0.5, size = 4.5)) +
   scale_y_continuous(limits = c(0, 20))


# print all plots on many rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 2, 
                        top = "Figure 5: Read depth per sample for both contig"
                        )) 
  
```

With the data that were not normalised by the median, there is no striking difference of read depth. For instance, sample A06 has more read counts in both contigs than the other samples. 




```{r check sample-based read depth for both contigs median normalised, eval = FALSE, echo = FALSE, warning = FALSE}
# name columns
colnames(both_contig_coverage_bymedian) <- c("sample_names", "extreme_contig", "extreme_contig_coverage", "normal_contig", "normal_contig_coverage")

# clean sample names
both_contig_coverage_bymedian$sample_names_cleaned <- gsub(x = both_contig_coverage_bymedian$sample_names, pattern = "coverage\\-|\\-interesting\\-contigs", replacement = "")

# remove samples not from Bruniquel
both_contig_coverage_bymedian_bruniquel <- subset(both_contig_coverage_bymedian, subset = sample_names_cleaned %in% c(monogynous.sample.vec, polygynous.sample.vec))

# change from wide to long format
both_contig_coverage_bymedian_long <- subset(both_contig_coverage_bymedian_bruniquel, select = c("sample_names_cleaned", "extreme_contig_coverage", "normal_contig_coverage"))

# add a social column
both_contig_coverage_bymedian_long$social <- gsub(x = both_contig_coverage_bymedian_long$sample_names_cleaned, pattern = ".*\\-", replacement = "")

# change to factor for the plotting
both_contig_coverage_bymedian_long$social <- factor(both_contig_coverage_bymedian_long$social, levels = both_contig_coverage_bymedian_long$social[order(both_contig_coverage_bymedian_long$social)])
both_contig_coverage_bymedian_long$sample_names_cleaned <- factor(both_contig_coverage_bymedian_long$sample_names_cleaned, levels = both_contig_coverage_bymedian_long$sample_names_cleaned[order(both_contig_coverage_bymedian_long$social)])

# test if distributions of each social type are continuous (null hypothesis) or different in location and shape
ks.test(x = both_contig_coverage_bymedian_long$extreme_contig_coverage, y = both_contig_coverage_bymedian_long$normal_contig_coverage)$p.value
wilcox.test(x = both_contig_coverage_long$extreme_contig_coverage, y = both_contig_coverage_long$normal_contig_coverage)$p.value

# keep a list to make plot
make_plot <- list()

# plot a barplot: x axis are samples, y axis are read count
plot_title    <- "Extreme contig"
x_title       <- "samples"
y_title       <- "Read depth mean"
make_plot[[1]] <- ggplot(both_contig_coverage_bymedian_long, aes(x = sample_names_cleaned, y = extreme_contig_coverage, fill = social)) +
   geom_bar(stat = "identity") +
   labs(title = plot_title, x = x_title, y = y_title) +
   theme_classic() + 
   # Monogynous orange f, Polygynous purple 9
   scale_fill_manual(values   = c("#f1a340", "#998ec3")) + 
   theme(axis.text.x  = element_text(angle = 45, vjust = 0.5, size = 4.5)) +
   scale_y_continuous(limits = c(0, 20))

# plot a barplot: x axis are samples, y axis are read count
plot_title    <- "Normal contig"
x_title       <- "samples"
y_title       <- "Read depth mean"
make_plot[[2]] <- ggplot(both_contig_coverage_bymedian_long, aes(x = sample_names_cleaned, y = normal_contig_coverage, fill = social)) +
   geom_bar(stat = "identity") +
   labs(title = plot_title, x = x_title, y = y_title) +
   theme_classic() + 
   # Monogynous orange f, Polygynous purple 9
   scale_fill_manual(values   = c("#f1a340", "#998ec3")) + 
   theme(axis.text.x  = element_text(angle = 45, vjust = 0.5, size = 4.5)) +
   scale_y_continuous(limits = c(0, 20))


# print all plots on many rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 2, 
                        top = "Figure 6: Read depth per sample for both contigs (median normalised)"
                        )) 
  
```

I wonder whether if I omit sample A09-P, the extreme contigs are less extreme.

```{r investigation of extreme read depth without A09-P, eval = FALSE, echo = FALSE, warning = FALSE}
# remove potential outlier sample
polygynous.coverage_noA09 <- polygynous.coverage[, -which(names(polygynous.coverage) %in% c("A09-P"))]
polygynous.sample.vec_noA09 <- polygynous.sample.vec[!grepl(x = polygynous.sample.vec, pattern = "^A09")]

### Normalise each read count by sample median
# copy the dataframe to overwrite it with normalised mean
polygynous.coverage_normalised <- polygynous.coverage_noA09

# loop through each P sample
for(this_sample in polygynous.sample.vec_noA09){
  # obtain the median of each sample
  this_sample_median <- median(unlist(polygynous.coverage_noA09[, this_sample]))
  # normalise each read count by median
  polygynous.coverage_normalised[this_sample] <- polygynous.coverage_noA09[, this_sample] / this_sample_median
}


# make a dataframe to keep the results
bruniquel_contig_coverage_noA09 <- as.data.frame(matrix(NA, ncol = 3, nrow = length(short_contig_vec)))

# name columns
colnames(bruniquel_contig_coverage_noA09) <- c("contig", "M_mean", "P_mean")

# add names of contigs
bruniquel_contig_coverage_noA09$contig <- short_contig_vec

# loop through each contig
for(this_contig in short_contig_vec){
  # calculate the mean of read counts for monogynous samples
  bruniquel_contig_coverage_noA09$M_mean[bruniquel_contig_coverage_noA09$contig == this_contig]   <- mean(unlist(monogynous.coverage_normalised[monogynous.coverage_normalised$contig == this_contig, monogynous.sample.vec]))
  # calculate mean of read counts for polygynous samples
  bruniquel_contig_coverage_noA09$P_mean[bruniquel_contig_coverage_noA09$contig == this_contig]   <- mean(unlist(polygynous.coverage_normalised[polygynous.coverage_normalised$contig == this_contig, polygynous.sample.vec_noA09]))
}

# calculate log2 fold change (P/M), normalised by median
bruniquel_contig_coverage_noA09$read_log2_fold_change <- log2( bruniquel_contig_coverage_noA09$M_mean / bruniquel_contig_coverage_noA09$P_mean)



### plot and look at outliers
# at the contig level, pick the top 10 contigs with largest departure from genome-wide read depth (less P read depth)
top_10_contig_vec_noA09 <- bruniquel_contig_coverage_noA09$contig[order(bruniquel_contig_coverage_noA09$read_log2_fold_change)][1:10]

# plot the result
# make a plot of read proportion (P / M)
plot_title    <- "Figure 7: Contig-level fold change of read depth in P samples with respect to M"
plot_subtitle <- "Data are read depth mean per contig, median normalised _noA09"
x_title       <- "unordered coding and non-coding contigs, from Bruniquel, maf > 0.05"
y_title       <- "Log2 fold change of read depth (P / M)"
ggplot(bruniquel_contig_coverage_noA09, aes(x = contig, y = read_log2_fold_change)) +
   geom_point(alpha = 0.4) +
   labs(title = plot_title, subtitle = plot_subtitle, x = x_title, y = y_title) +
   theme_classic() +
   theme(axis.text.x = element_blank()) +
   geom_hline(yintercept = 0, colour = "cyan")


# add contig length info
bruniquel_contig_coverage_noA09$length <- intersected_contig_length_df$length[match(bruniquel_contig_coverage_noA09$contig, intersected_contig_length_df$short_contig_name)]

# remove contigs shorter than 10kb
bruniquel_contig_coverage_noA09_10kb <- subset(bruniquel_contig_coverage_noA09, subset = length > 10000)

# pick out the top ten contigs 
top_10_contig_vec_noA09_10kb <- bruniquel_contig_coverage_noA09_10kb$contig[order(bruniquel_contig_coverage_noA09_10kb$read_log2_fold_change)][1:10]

# plot the result
# make a plot of read proportion (P / M)
plot_title    <- "Figure 8: Contig-level fold change of read depth in P samples with respect to M"
plot_subtitle <- "Data are read depth mean per contig, normalised by median _noA09"
x_title       <- "unordered coding and non-coding contigs, from Bruniquel, maf > 0.05, longer than 10kb"
y_title       <- "Log2 fold change of read depth (P / M)"
ggplot(bruniquel_contig_coverage_noA09_10kb, aes(x = contig, y = read_log2_fold_change)) +
   geom_point(alpha = 0.4) +
   labs(title = plot_title, subtitle = plot_subtitle, x = x_title, y = y_title) +
   theme_classic() +
   theme(axis.text.x = element_blank()) +
   geom_hline(yintercept = 0, colour = "cyan")
    

```

By removing the potential sample outlier A09-P, the effect on the contig-level log2 fold change of read depth is insignificant: visually the plot looks the same, and the extreme contig has still a very low value (-0.65).

So it is possible that the difference in contig read depth is based on singular variants.
On IGV, only 19 samples show some difference in the extreme contig 1346. They are all polygynous from Bruniquel (19 out of 54 P Bruniquel), and have very little coverage for the first 10kb of this contig. 
A quick blast shows no gene hit at this position. Further down the contig, there is a "PREDICTED: Vollenhovia emeryi histone-lysine N-methyltransferase SETMAR-like (LOC105565278), mRNA".


```{r read depth sliding window, eval = FALSE, echo = FALSE, warning = FALSE}
# add rownames
row.names(contig_1346_5kb_coverage) <- c("0-5kb", "5-10kb", "10-15kb", "15-20kb", "20-25kb")

# samples
colnames(contig_1346_5kb_coverage) <- gsub(x = colnames(contig_1346_5kb_coverage), pattern = "\\.", replacement = "-")

# number of window 
num_of_windows <- 5

# transform the wide df into long df
contig_1346_5kb_coverage_long <- as.data.frame(matrix(ncol = 3, nrow = length(colnames(contig_1346_5kb_coverage)) * num_of_windows))

# name columns
colnames(contig_1346_5kb_coverage_long) <- c("window", "sample", "read_depth")

# fill in the window column
contig_1346_5kb_coverage_long$window <- c(rep("0-5kb", length(colnames(contig_1346_5kb_coverage))),
                                          rep("5-10kb", length(colnames(contig_1346_5kb_coverage))),
                                          rep("10-15kb", length(colnames(contig_1346_5kb_coverage))),
                                          rep("15-20kb", length(colnames(contig_1346_5kb_coverage))),
                                          rep("20-25kb", length(colnames(contig_1346_5kb_coverage))))

# fill in the sample column
contig_1346_5kb_coverage_long$sample <- rep(colnames(contig_1346_5kb_coverage), num_of_windows)

# fill in the read depth
contig_1346_5kb_coverage_long$read_depth <- unlist(c(subset(contig_1346_5kb_coverage, subset = rownames(contig_1346_5kb_coverage) == "0-5kb"),
                                              subset(contig_1346_5kb_coverage, subset = rownames(contig_1346_5kb_coverage) == "5-10kb"),
                                              subset(contig_1346_5kb_coverage, subset = rownames(contig_1346_5kb_coverage) == "10-15kb"),
                                              subset(contig_1346_5kb_coverage, subset = rownames(contig_1346_5kb_coverage) == "15-20kb"),
                                              subset(contig_1346_5kb_coverage, subset = rownames(contig_1346_5kb_coverage) == "20-25kb")))

# add a column for social form
contig_1346_5kb_coverage_long$social <- gsub(x = contig_1346_5kb_coverage_long$sample, pattern = ".*\\-", replacement = "")

# add a column for population
contig_1346_5kb_coverage_long$population <- pop_info_df$population[match(contig_1346_5kb_coverage_long$sample, pop_info_df$sample.soc)]


# order y axis (the samples) by social form and by population
mono_samples <- grep(pattern = "\\-M", x = contig_1346_5kb_coverage_long$sample, value = TRUE)
poly_samples <- grep(pattern = "\\-P", x = contig_1346_5kb_coverage_long$sample, value = TRUE)
# mono_samples_bruniquel     <- grep(pattern = "\\-M", x = contig_1346_5kb_coverage_long$sample[contig_1346_5kb_coverage_long$population == "Bruniquel"], value = TRUE)
# mono_samples_not_bruniquel <- grep(pattern = "\\-M", x = contig_1346_5kb_coverage_long$sample[contig_1346_5kb_coverage_long$population != "Bruniquel"], value = TRUE)
# poly_samples_bruniquel     <- grep(pattern = "\\-P", x = contig_1346_5kb_coverage_long$sample[contig_1346_5kb_coverage_long$population == "Bruniquel"], value = TRUE)
# poly_samples_not_bruniquel <- grep(pattern = "\\-P", x = contig_1346_5kb_coverage_long$sample[contig_1346_5kb_coverage_long$population != "Bruniquel"], value = TRUE)

contig_1346_5kb_coverage_long$sample <- factor(contig_1346_5kb_coverage_long$sample, levels = c(mono_samples, poly_samples))

# another window for population
window_for_pop <- subset(contig_1346_5kb_coverage_long, subset = window == "0-5kb")
window_for_pop$window <- "black_is_bruniquel"
window_for_pop$read_depth <- 0
window_for_pop$read_depth[window_for_pop$population == "Bruniquel"] <- 3

contig_1346_5kb_coverage_long_with_pop <- rbind(contig_1346_5kb_coverage_long, window_for_pop)
  
  
# make a heatmap for this contig contig_1346_5kb_coverage 
plot_title  <- "contig_1346"
xaxis_label <- "5kb window"
yaxis_label <- "Individual"
ggplot(contig_1346_5kb_coverage_long_with_pop, aes(window, sample)) +
  geom_tile(aes(fill = read_depth)) +
  labs(title = plot_title, x = xaxis_label, y = yaxis_label) +
  theme_classic() +
  theme(axis.text.y = element_text(size = 4)) +
  scale_fill_gradient(low = "white", high = "black")
  
```





```{r check read depth for extreme contig, eval = FALSE, echo = FALSE, warning = FALSE}


### Step 3: check read depth for extreme contig: contig_1346
# subset for extreme contig contig_1346
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_237_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_237_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 261
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"

  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on many rows
do.call(grid.arrange, c(make_plot[1:5], 
                        nrow = 5, 
                        top = "Read depth distribution for 261 variants in 1st extreme contig",
                        bottom = "Contig_1346: fold change -0.6598197, mapping quality: 9.18000, length: 29,336 bp"
                        )) 

### Step 4: check read depth for extreme contig: contig_4096
# subset for extreme contig contig_4516
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_4096_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_4096_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 3
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"

  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on 3 rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 3, 
                        top = "Read depth distribution for 3 variants in 2nd extreme contig",
                        bottom = "Contig_4096: fold change -0.5641395, mapping quality: 291.786843, length: 5,003 bp"


                        )) 

### Step 5: check read depth for extreme contig: contig_4067
# subset for extreme contig contig_4067
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_4067_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_4067_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 3
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"
  
  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on 3 rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 4, 
                        top = "Read depth distribution for 7 variants in 3rd extreme contig",
                        bottom = "Contig_4067: fold change -0.5526302, mapping quality: 60.052584, length: 3,593 bp"
                        )) 



# Now do the same for 3 normal contigs (fold change = 0)
normal_contig_info_df <- subset(contig_read_fold_change_df, subset = read_log2_fold_change == 0)[6:9, ]


# subset for normal contig contig_1260
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_170_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_170_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 1
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"
  
  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on 3 rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 2, 
                        top = "Read depth distribution for 1 variant in normal contig",
                        bottom = "Contig_170: fold change 0, mapping quality: ??, length: ?? bp"
                        )) 



# subset for normal contig contig_13
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_1890_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_1890_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 2
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"
  
  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on 3 rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 2, 
                        top = "Read depth distribution for 2 variant in normal contig",
                        bottom = "Contig_1890: fold change 0, mapping quality: ??, length: ?? bp"
                        )) 


# subset for normal contig contig_15
monogynous.coverage_extreme_contig <- subset(monogynous.coverage, subset = chr == "contig_1781_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")
polygynous.coverage_extreme_contig <- subset(polygynous.coverage, subset = chr == "contig_1781_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon")

# obtain all read depth for each SNP in this contig
coverage_extreme_contig <- merge(x = monogynous.coverage_extreme_contig, y = polygynous.coverage_extreme_contig, by = "SNP_name")

# how many variants in this contig = 2
variant_in_this_contig_num <- length(unique(coverage_extreme_contig$SNP_name))

# name columns
colnames(sample_list_vec) <- "sample_name"

# keep a vector for the means of read depth per variant
mean_read_depth_of_this_contig <- c()

# keep a list to make plot
make_plot <- list()

# loop through the variants
for(position in 1:variant_in_this_contig_num){
  # mean of read depth per variant
  variant_one_info <- as.data.frame(t(subset(coverage_extreme_contig, subset = SNP_name == coverage_extreme_contig$SNP_name[position], select = colnames(coverage_extreme_contig) %in% sample_list_vec$sample_name)))

  # colnames
  colnames(variant_one_info) <- "read_depth"
  
  # add a column for social
  variant_one_info$social <- gsub(pattern = ".*\\-", x = rownames(variant_one_info), replacement = "")

  # read depth mean for this variant in this extreme contig
  mean_read_depth_of_this_contig <- c(mean_read_depth_of_this_contig, mean(variant_one_info$read_depth))
  
  # plot distribution of read depth
  make_plot[[position]] <- ggplot(variant_one_info, aes(x = as.factor(read_depth), fill = factor(social))) +
    geom_bar(position = "dodge") +
    theme_classic()
}

# print all plots on 3 rows
do.call(grid.arrange, c(make_plot, 
                        nrow = 2, 
                        top = "Read depth distribution for 1 variant in normal contig",
                        bottom = "Contig_1781: fold change 0, mapping quality: ??, length: ?? bp"
                        )) 

```


```{r, eval = FALSE, echo = FALSE, warning = FALSE}
# ### Step 4: check heterozygosity level
# # in x axis, the loci
# # in y axis, the frequency of the most common allele
# # in snp_matrix, I can obtain the most common genotype for a given locus, either 0/0 or 0/1 or 1/1
# snp_matrix_geno <- snp_matrix[ , 3:ncol(snp_matrix)]
# # change the sample names for biological names by sourcing the colony names
# colnames(sample_list_vec) <- "sample_name"
# # create a vector of colony names
# colony_names <- as.character(sample_list_vec$sample_name)
# # keep in vector the names of colony in each social type
# mono_samples <- grep(pattern = "-M", x = colony_names, value = TRUE)
# poly_samples <- grep(pattern = "-P", x = colony_names, value = TRUE)
# # name the SNP matrix
# colnames(snp_matrix_geno) <- colony_names
# rownames(snp_matrix_geno) <- snp_matrix$V1
# # change vcf code for a 0/1/2
# snp_matrix_geno[snp_matrix_geno == "0/0"] <- 0 
# snp_matrix_geno[snp_matrix_geno == "0/1"] <- 1
# snp_matrix_geno[snp_matrix_geno == "1/1"] <- 2
# 
# # collect all frequencies in a dataframe
# freq_mat <- matrix(NA, nrow = nrow(snp_matrix_geno), ncol = 2)
# # loop through locus
# for(position in 1:nrow(snp_matrix_geno)){
#   # subset to one locus
#   one_locus <- snp_matrix_geno[position, ]
#   # transform to long format
#   one_locus_t <- as.data.frame(t(one_locus), stringsAsFactors = FALSE)
#   # name the column
#   colnames(one_locus_t) <- "alt"
#   # create a new column for reference allele
#   one_locus_t$ref <- 0
#   # code the reference allele based on the alt allele code
#   # if the alt allele is coded 0, it means that the sample has 2 reference alleles
#   one_locus_t$ref[one_locus_t$alt == "0"] <- 2
#   # if the alt allele is coded 1, it means that the sample has 1 reference allele
#   one_locus_t$ref[one_locus_t$alt == "1"] <- 1
#   # if the alt allele is coded 2, it means that the sample has 0 reference allele
#   one_locus_t$ref[one_locus_t$alt == "2"] <- 0
#   
#   # change character to numeric
#   one_locus_t$alt <- as.numeric(one_locus_t$alt)
# 
#   # obtain sum of each allele
#   sum_alleles <- c(sum(one_locus_t$alt), sum(one_locus_t$ref))
#     
#   # find the most common allele column
#   most_common_allele_column <- which.max(sum_alleles)
#   
#   # calculate the sum of most frequent allele for monogynous samples
#   sum_freq_allele_M <- sum(one_locus_t[rownames(one_locus_t) %in% mono_samples, most_common_allele_column])
#   # calculate the frequency of the most frequent allele in the monogynous samples (diploid, so 2 alleles * number of samples)
#   freq_common_allele_M <- sum_freq_allele_M / (length(mono_samples)*2)
#   # calculate the sum of most frequent allele for polygynous samples
#   sum_freq_allele_P <- sum(one_locus_t[rownames(one_locus_t) %in% poly_samples, most_common_allele_column])
#   # calculate the frequency of the most frequent allele in the polygynous samples (diploid, so 2 alleles * number of samples)
#   freq_common_allele_P <- sum_freq_allele_P / (length(poly_samples)*2)
#   # save the two frequencies
#   freq_mat[position, ] <- c(freq_common_allele_M, freq_common_allele_P)
# }
# 
# # make into a dataframe
# freq_df <- as.data.frame(freq_mat, stringsAsFactors = FALSE)
# 
# # name columns
# colnames(freq_df) <- c("Monogynous", "Polygynous")
# 
# # add loci as new column
# freq_df$loci <- rownames(snp_matrix_geno)
# 
# # add contig as a new column
# freq_df$contig <- gsub(pattern = "_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon:.*", x = freq_df$loci, replacement = "")
# 
# # subset for the top contig
# freq_df_top_contigs <- subset(freq_df, subset = contig %in% top_10_contig_info_df$contig)
# 
# # give factor to loci for ggplot order
# freq_df_top_contigs$loci   <- factor(freq_df_top_contigs$loci, levels = freq_df_top_contigs$loci)
# freq_df_top_contigs$contig <- factor(freq_df_top_contigs$contig, levels = freq_df_top_contigs$contig)
# 
# # plot the frequency of most common allele for each locus
# x_title <- "In top 10 contig, SNPs not ordered"
# y_title <- "Frequency of most common allele"
# main_title <- "Heterozygosity of most common alleles"
# 
# # colours for the contigs
# contig_colour_vec <- c("#543005", "#CC79A7", "#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#003c30")
# # plot the lollipops
# ggplot(freq_df_top_contigs) +
#     geom_segment( aes(x = loci, xend = loci, y = Monogynous, yend = Polygynous, color = contig), size = 0.4) +
#     geom_point( aes(x = loci, y = Monogynous), color = 'brown', size = 0.5 ) +
#     geom_point( aes(x = loci, y = Polygynous), color = 'blue', size = 0.5 ) +
#     theme_classic() +
#     theme(axis.text.x = element_blank(), axis.title.y = element_blank()) +
#     labs(title = main_title, x = x_title, y = y_title) +
#     ylim(0, 1) +
#     scale_color_manual(name = "", values = contig_colour_vec)
# 

 

# check at the SNP level of the top contig: genotype, gene content?



```


Those contigs should be understood better:
1) read depth per variant within the extreme contig
- how many variants in each contig?
- how many variants have extreme values (distribution of read depth)?

2) read depth per sample within the extreme contig
- if the distribution is narrow (small variance), could it be one sample that is an outlier? I could use the IQR to find outliers.

# Literature review of read depth

A Comprehensive Workflow for Read Depth-Based Identification of Copy-Number Variation from Whole-Genome Sequence Data https://doi.org/10.1016/j.ajhg.2017.12.007

Reasons why read depth could be useful to investigate for variants (and limitations with difference between single-nucleotide polymorphism and copy-number variation)
DNA library preparation = amplification bias from PCR-based prep (in this comparative study, the library preps with PCR-step led to an excess of CNVs); insert size (in this comparative study, the number of deletions detected depended on the median insert size of the DNA library)
sequencing depth
quality control
reference mapping
variant identification = CNV > 1kb are most ameable/easy to test to detection by read depth; smaller CNV are more likely to be detected by methods that are not read depth based; read depth detection can be confounded by repetitive regions and low-complexity regions; check what the software do; read-depth uniformity for a whole sample: inter-quartile range (IQR = R75 - R25, where R75 is the read depth for which 75% of the bases in the reference genome have smaller depths. Quality threshold would be IQR < 15 for a sequencing effort of 30x)
Reasons upstream why read depth could be different 