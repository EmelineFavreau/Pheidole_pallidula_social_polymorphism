#!/bin/sh

###############################################################################
### Project preparation ###
module load bcftools/1.8
module load vcftools/0.1.15
module load R/3.5.1
# tabix 0.2.5
module load plink/1.9-170906

mkdir input
cd input
ln -s ../../../input/2019-03-08-109samples-maf10percent/complete.vcf .
cd ..

mkdir result

mkdir -p ~/monthly_autoScratch/2019-03-05-association_analysis_flye_assembly/2019-03-08-109samples-maf10percent

ln -s ~/monthly_autoScratch/2019-03-05-association_analysis_flye_assembly/2019-03-08-109samples-maf10percent tmp

mkdir -p ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent

# copy important files
cp ~/2018-11-09-association_analysis_mixed_assembly/result/2019-02-06-109samples-maf10percent/pheno.txt .

cp ~/2018-11-09-association_analysis_mixed_assembly/result/2019-02-06-109samples-maf10percent/exploring-pca-results.Rmd .

cp ~/2018-11-09-association_analysis_mixed_assembly/result/2019-02-06-109samples-maf10percent/input/S2_pheidole_pop_paper.csv .

cp ~/2018-11-09-association_analysis_mixed_assembly/result/2019-02-06-109samples-maf10percent/assoc-analysis.Rmd .

todayanalysis="2019-03-14-bruniquel"

###############################################################################
### Filtering vcf ###

# Step 1: index the vcf
# The input data file must be position sorted
# tmux new -s bcftools; this task takes some times
bcftools sort input/complete.vcf -T /tmp/ -o tmp/sorted-complete.vcf
# compress by bgzip
bgzip tmp/sorted-complete.vcf
# index the vcf
tabix -p vcf tmp/sorted-complete.vcf.gz

## 1 - check the file visually and understand each variant info
bcftools view -H tmp/sorted-complete.vcf.gz | head -1
#GT: genotype at this type, 0/0 homozygote reference
#DP: depth of coverage at sample level, unfiltered
#AD: unfiltered allele depth
#RO:Reference allele observation count
#QR:Sum of quality of the reference observations
#AO:Alternate allele observation count
#QA:Sum of quality of the alternate observations
#GL:Genotype Likelihood, log10-scaled likelihoods of the data given the called
# genotype for each possible genotype generated from the reference and
# alternate alleles given the sample ploidy

## 2 - count number of lines without # to have an idea of number of SNPs
grep -v "^#" input/complete.vcf | wc -l
# 27006673 MinION
# 29983468 Illumina

## 3 - check sample list, not in alphabetical order because filtered by position
bcftools query -l tmp/sorted-complete.vcf.gz
# check quality High QUAL scores indicate high confidence calls
bcftools query -f '%QUAL\n' tmp/sorted-complete.vcf.gz | sort | uniq -c \
         > vcf-qual.txt
bcftools query -f '%QUAL\n' tmp/sorted-complete.vcf.gz | sort | uniq -c \
         | sort -k1 > vcf-qual2.txt
bcftools query -f '%QUAL\n' tmp/sorted-complete.vcf.gz | sort | uniq -c \
         | sort --key=1 --numeric-sort > vcf-qual3.txt

## 4 - investigate read depth
vcftools --gzvcf tmp/sorted-complete.vcf.gz \
          --site-depth \
          --out tmp/2019-02-06-109samples-maf10percent

cat tmp/2019-02-06-109samples-maf10percent.ldepth | sort --key=3 \
          > vcf-depth.txt

vcftools --gzvcf tmp/sorted-complete.vcf.gz \
          --site-mean-depth \
          --out tmp/2019-02-06-109samples-maf10percent

cat tmp/2019-02-06-109samples-maf10percent.ldepth.mean | sort --key=3 \
          > vcf-depth-mean.txt

cp tmp/*coverage.csv result/.

## 5 - investigate which quality threshold to use
qual-investigation.R

## 5b - keep only samples from Bruniquel
cat S2_pheidole_pop_paper.csv | grep -E "Bruniquel" | cut -d "," -f 1 > bruniquel-colonies.txt

## 6 - filtering options
# only biallelic SNPs, phred quality > 30, 75% sample support
# Exclude sites on the basis of the proportion of missing data
# defined to be between 0 and 1, where 0 allows sites that are completely
# missing and 1 indicates no missing data allowed)
# filter out 6 samples that are outliers in mds:
# CU132-P, I17-M, E39-M, E139-P, muna-N, andrea-N [outliers-samples.txt]
# filter singletons: include only sites with a minor allele frequency of >0.05
vcftools --gzvcf tmp/sorted-complete.vcf.gz \
         --remove-indels \
         --minQ 30 \
         --max-missing 0.75 \
         --min-alleles 2 \
         --max-alleles 2 \
         --remove outliers-samples.txt \
         --keep bruniquel-colonies.txt \
         --maf 0.05 \
         --recode \
         --recode-INFO-all \
         --out tmp/${todayanalysis}-maf10percent
# 812,760 out of a possible 27006673 Sites
# 1640 seconds
# 27 minutes

# get sample names
bcftools query -l tmp/${todayanalysis}-maf10percent.recode.vcf \
              > tmp/${todayanalysis}-sample_names.txt
# get snp matrix
bcftools query result/2019-03-14-bruniquel-maf10percent.recode.vcf -f '%ID\t%POS[\t%GT]\n' > result/${todayanalysis}-snp_matrix.txt

# copy to archive
cd tmp

rsync -avx --human-readable --progress ${todayanalysis}-maf10percent.recode.vcf ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent/.

rsync -avx --human-readable --progress ${todayanalysis}-sample_names.txt ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent/.

# softlink to result
cd ../result

ln -s ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent/${todayanalysis}-maf10percent.recode.vcf

ln -s ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent/${todayanalysis}-sample_names.txt

cd ..


###############################################################################
## prune away LD snps indep-pairwise ##


# step 1: assign chromosome-and-position-based IDs (currently not named)
plink --vcf result/${todayanalysis}-maf10percent.recode.vcf \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --make-bed \
      --out tmp/${todayanalysis}-pheidole

plink --bfile tmp/${todayanalysis}-pheidole \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --make-bed \
      --set-missing-var-ids @:#\$1,\$2 \
      --out tmp/${todayanalysis}-pheidole-id

# step 2 --make-founders
# With no modifiers, --make-founders clears both parental IDs whenever at least
#  one parent is not in the dataset, and the affected samples are now
# considered founders.
# Note: Skipping --make-founders since there are no nonfounders.
plink --bfile tmp/${todayanalysis}-pheidole-id \
      --allow-extra-chr \
      --allow-no-sex \
      --make-founders \
      --pheno pheno.txt \
      --make-bed \
      --out tmp/${todayanalysis}-pheidole-no-founder

# step 3 - pruning away SNPs in LD
# people seem to use 0.2 as a threshold
# under a minute.   481,746 of 777,165  variants removed
plink --bfile tmp/${todayanalysis}-pheidole-no-founder \
      --allow-extra-chr \
      --allow-no-sex \
      --indep-pairwise 50 5 0.2 \
      --out tmp/${todayanalysis}-pheidole-snp-in-ld

cp tmp/${todayanalysis}-pheidole-snp-in-ld.prune.in result/.

# step 4 - filter data by keeping only the SNPs that are not in disequilibrium
# 295,419 variants and 70 people
plink --bfile tmp/${todayanalysis}-pheidole-no-founder \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --extract tmp/${todayanalysis}-pheidole-snp-in-ld.prune.in \
      --make-bed \
      --out tmp/${todayanalysis}-pruned-pheidole-data

cp tmp/${todayanalysis}-pruned-pheidole-data.bim result/.
cp tmp/${todayanalysis}-pruned-pheidole-data.bed result/.
cp tmp/${todayanalysis}-pruned-pheidole-data.fam result/.



###############################################################################
## pca ##

# step 1 create a genome file - IBD will be calculated
plink --bfile result/${todayanalysis}-pruned-pheidole-data \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --genome \
      --extract result/${todayanalysis}-pheidole-snp-in-ld.prune.in \
      --out tmp/${todayanalysis}-pheidoleIBD

# step 2 use --pca to generate an eigenvec file containing PCs
# header adds a header line to the .eigenvec file(s)
# --cluster uses IBS values calculated to perform complete linkage clustering
# .cluster2 describes only the final cluster configuration
plink --bfile result/${todayanalysis}-pruned-pheidole-data \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --cluster \
      --pca header \
      --extract result/${todayanalysis}-pheidole-snp-in-ld.prune.in \
      --read-genome tmp/${todayanalysis}-pheidoleIBD.genome \
      --out tmp/${todayanalysis}-pheidolePCA

cp tmp/${todayanalysis}-pheidolePCA* result/.

# make sense of the pca eigenvalue and ultimately
# how much of the variance is explained by each PC? PC1 3%, PC2 1%
Rscript exploring-pca-results.Rmd


###############################################################################
## run association test ##

# Step 1: Perform the association analysis using 2 main PCs
# from the eigenvec file as covariates
# covariate can only be used with a regression model, here logistics --logistic
plink --bfile result/${todayanalysis}-pruned-pheidole-data \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --covar result/bruniquel.eigenvec.tops.csv \
      --covar-name PC1,PC2 \
      --logistic \
      --out tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues

# Step 2: understanding the output of the model
# ADD means the additive effects of allele dosage (counts of each allele)
# the direction of the regression coefficient represents
# the effect of each extra minor allele
# (i.e. a positive regression coefficient means that
# the minor allele increases risk/phenotype mean
# PLINK will also output the beta-coefficients for the adjustment variables
# that is why there are more lines than snps 886258
wc -l tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues.assoc.logistic
# remove the lines about PC1 and PC2 815078
grep ADD tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues.assoc.logistic > \
 tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues.assoc.filtered.logistic
# 295419 SNPs
wc -l tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues.assoc.filtered.logistic

# copy to result
cp tmp/${todayanalysis}-LDpruned-maf0.05-snp-pvalues.assoc.filtered.logistic result/.



###############################################################################
## association analysis ##

# adjusting p-values from plink output
# association test on each SNP for allele count per gyny group)
Rscript assoc-analysis.Rmd













# pruning the LD was a bit intense. Now relaxing the pruning:
# step 3 - pruning away SNPs in LD
# varying r2, how well the regression predictions approximate the real data
# it usually varies between 0 and 1 (perfect fit)
# people seem to use 0.2 as a threshold
# I will try larger (should get more SNPs in)
# under a minute.   448,563 of 812,760  variants removed
plink --bfile tmp/pheidole-no-founder \
      --allow-extra-chr \
      --allow-no-sex \
      --indep-pairwise 50 5 0.3 \
      --out tmp/pheidole-snp-in-ld-0.3

cp tmp/pheidole-snp-in-ld-0.3.prune.in result/.

# step 4 - filter data by keeping only the SNPs that are not in disequilibrium
# 364,197 variants and 109 people
plink --bfile tmp/pheidole-id \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --extract tmp/pheidole-snp-in-ld-0.3.prune.in \
      --make-bed \
      --out tmp/pruned-0.3-pheidole-data

cp tmp/pruned-0.3-pheidole-data.bim result/.
cp tmp/pruned-0.3-pheidole-data.bed result/.
cp tmp/pruned-0.3-pheidole-data.fam result/.



###############################################################################
## pca obtain kinship matrix ##

# step 1 create a genome file - IBD will be calculated
plink --bfile result/pruned-0.3-pheidole-data \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --genome \
      --extract result/pheidole-snp-in-ld-0.3.prune.in \
      --out tmp/pheidole-0.3-IBD

# step 2 use --pca to generate an eigenvec file containing PCs
# header adds a header line to the .eigenvec file(s)
# --cluster uses IBS values calculated to perform complete linkage clustering
# .cluster2 describes only the final cluster configuration
plink --bfile result/pruned-0.3-pheidole-data \
      --allow-extra-chr \
      --allow-no-sex \
      --pheno pheno.txt \
      --cluster \
      --pca header \
      --extract result/pheidole-snp-in-ld-0.3.prune.in \
      --read-genome tmp/pheidole-0.3-IBD.genome \
      --out tmp/pheidole-0.3-PCA

cp tmp/pheidole-0.3-PCA* result/.

# make sense of the pca eigenvalue and ultimately
# how much of the variance is explained by each PC? PC1 8%, PC2 3%
Rscript  exploring-pca-results-03.Rmd


###############################################################################
## run association test ##

# Step 1: Perform the association analysis using 2 main PCs
# from the eigenvec file as covariates
# covariate can only be used with a regression model, here logistics --logistic
plink --bfile result/pruned-0.3-pheidole-data \
      --allow-extra-chr --allow-no-sex \
      --pheno pheno.txt \
      --covar result/pheidole.0.3.eigenvec.tops.csv \
      --covar-name PC1,PC2 \
      --logistic \
      --out tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues

# Step 2: understanding the output of the model
# ADD means the additive effects of allele dosage (counts of each allele)
# the direction of the regression coefficient represents
# the effect of each extra minor allele
# (i.e. a positive regression coefficient means that
# the minor allele increases risk/phenotype mean
# PLINK will also output the beta-coefficients for the adjustment variables
# that is why there are more lines than snps 1092592
wc -l tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues.assoc.logistic
# remove the lines about PC1 and PC2 815078
grep ADD tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues.assoc.logistic > \
 tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues.assoc.filtered.logistic
# 364197 SNPs
wc -l tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues.assoc.filtered.logistic

# copy to result
cp tmp/pheidole-109samples-LDpruned0.3-maf0.05-snp-pvalues.assoc.filtered.logistic result/.



###############################################################################
## association analysis ##

# adjusting p-values from plink output
# association test on each SNP for allele count per gyny group)
Rscript assoc-analysis03.Rmd







###############################################################################
## Genome coverage study ##
# Difference in base coverage between monogynous and polygynous?


# update tmp (autoscratch does not exist anymore)
unlink tmp
mkdir -p ~/scratch/2019-03-05-association_analysis_flye_assembly/result/2019-03-14-bruniquel-maf10percent
ln -s ~/scratch/2019-03-05-association_analysis_flye_assembly/result/2019-03-14-bruniquel-maf10percent tmp


# Create VCFs for monogynous (n = 15) and polygynous (n = 53) samples
bcftools query --list-samples result/2019-03-14-bruniquel-maf10percent.recode.vcf | grep -E "\-M" > monogynous-samples-from-vcf

bcftools query --list-samples result/2019-03-14-bruniquel-maf10percent.recode.vcf | grep -E "\-P" > polygynous-samples-from-vcf

vcftools --vcf result/2019-03-14-bruniquel-maf10percent.recode.vcf \
         --keep monogynous-samples-from-vcf \
         --recode \
         --recode-INFO-all \
         --out tmp/monogynous-samples-bruniquel-codingnoncoding

vcftools --vcf result/2019-03-14-bruniquel-maf10percent.recode.vcf \
        --keep polygynous-samples-from-vcf \
        --recode \
        --recode-INFO-all \
        --out tmp/polygynous-samples-bruniquel-codingnoncoding


# Obtain read depth from VCF for each social type
bcftools query -f '%CHROM %POS[\t%DP]\n' tmp/monogynous-samples-bruniquel-codingnoncoding.recode.vcf > result/monogynous-samples-bruniquel-codingnoncoding.read.depth

bcftools query -f '%CHROM %POS[\t%DP]\n' tmp/polygynous-samples-bruniquel-codingnoncoding.recode.vcf > result/polygynous-samples-bruniquel-codingnoncoding.read.depth

# Obtain sample list
bcftools query -l tmp/monogynous-samples-bruniquel-codingnoncoding.recode.vcf > result/monogynous-samples-bruniquel-codingnoncoding.sample.list

bcftools query -l tmp/polygynous-samples-bruniquel-codingnoncoding.recode.vcf > result/polygynous-samples-bruniquel-codingnoncoding.sample.list


# plot the read depth x mono, y poly
cp ../2019-04-03-coding-only-bruniquel-maf10percent/genome-coverage-between-MP-real.Rmd .
Rscript genome-coverage-between-MP.Rmd

# mapping quality exploration (mean mapping quality per sample: alternative and reference)
bcftools query -f '%CHROM[\t%MQM%MQMR]\n' result/2019-03-14-bruniquel-maf10percent.recode.vcf > test

# calculate the mapping quality mean by SNP
# take a line at a time
# ommiting the first column (it is the name of the SNP)
awk 'NR==1 { next }
        { T=0
           for(N=2; N<=NF; N++) T+=$N;
           T/=(NF-1)
           print $1, T }' test > snp-mapping-quality-mean

# read depth exploration
bcftools query -f '%CHROM %POS[\t%DP]\n' result/2019-03-14-bruniquel-maf10percent.recode.vcf > read-depth-per-variant



#### generate index from vcf
bgzip -c result/2019-03-14-bruniquel-maf10percent.recode.vcf > result/2019-03-14-bruniquel-maf10percent.recode.vcf.bgz
tabix -p vcf result/2019-03-14-bruniquel-maf10percent.recode.vcf.bgz





################################################################################
### Calculate read depth for extreme contig
# expectation: one sample has way more read counts than other samples
# need bedtools2 to have no bug (installing from github 2.28)

## data preparation



# copy the genome index to create the genome size file needed by bedtools
cp ../2019-03-15-map_reads_to_minion_flye/result/reference_pilon_pilon.fasta.fai input/.
# soft link all alignment files
cd input
ln -s ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-07-variant_calling/*.bam .
ln -s ~/archive/2019-03-05-association_analysis_flye_assembly/2019-03-07-variant_calling/*.bai .

cd ..

# make a file with all samples names
ls input/*bam | cut -d "/" -f 2 | cut -d "." -f 1 > samples

# subset bam file for just the two contigs
for sample in $(cat samples); do
  samtools view -bh input/${sample}*.bam contig_1346_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon > tmp/${sample}-subset.bam
done


# calculating the read depth of each sample for the extreme contig contig_1346
# -d per-base reports
# input is bam, so no need to add genome file
# even with the shorter bam, the output contains all the contigs!
# output: chr | chr pos | depth
~/software/bedtools2/bin/genomeCoverageBed -d -ibam tmp/A01-P-subset.bam > tmp/coverage-per-base-subset-A01-P

# keep only contigs
grep -E "contig_1346|contig_1470" tmp/coverage-per-base-subset-A01-P >> tmp/coverage-per-base-subset-A01-P-short

# then use groupby to calculate mean of read depth (c 3) per contig (g 1)
~/software/bedtools2/bin/groupBy -i tmp/coverage-per-base-subset-A01-P-short -g 1 -c 3 -o mean > tmp/coverage-A01-P-interesting-contigs

# if this works, I need to automate it to all 115 bams
# make a variable with sample names
ls input/*bam | cut -d "/" -f 2 | cut -d "." -f 1 > samples

# make an array job! 80Gb per job I hope that it is enough - yes
chmod +x calculate-mean.sh
qsub calculate-mean.sh

# make another array job for mean normalised by median+1
chmod +x converage-normalised-bymedian.sh
qsub converage-normalised-bymedian.sh

# get the samples names
cd tmp
ls coverage*interesting-contigs > samples

# get the read depth mean from extreme contig
cat coverage*interesting-contigs | grep -E "contig_1346" > extreme_contig-coverage
cat coverage*interesting-contigs | grep -E "contig_1346" > extreme_contig-coverage-bymedian

# get the read depth mean from normal contig
cat coverage*interesting-contigs | grep -E "contig_1470" > normal_contig-coverage
cat coverage*interesting-contigs | grep -E "contig_1470" > normal_contig-coverage-bymedian

# gather all info into one file
cd ..

paste tmp/samples tmp/extreme_contig-coverage tmp/normal_contig-coverage > result/both-contig-coverage

paste tmp/samples tmp/extreme_contig-coverage-bymedian tmp/normal_contig-coverage-bymedian > result/both-contig-coverage-bymedian

# use R to plot histograms (x = samples, y = read count)
genome-coverage-between-MP-real.Rmd



################################################################################

# based on R plot, 5 contigs the most enriched for P reads
# contig_1346 contig_237 contig_2241 contig_3784 contig_1697
# based on R plot, 5 contigs the most enriched for M reads
# contig_4645 contig_1752 contig_43 contig_4728 contig_1768
# based on R plot, 5 contigs that are balanced between social forms
# contig_1158 contig_1193 contig_1223 contig_1470 contig_1654 contig_2111

# I made bed files for each of them in the R script genome-coverage-between-MP-real.Rmd, now I need to figure out how to run the pipeline for all 10 contigs



chmod +x calculate_mean_for_10_contigs.sh
tmux new
./calculate_mean_for_10_contigs.sh

# combine name of sampled and results in one file
chmod +x combine_read_calculation_into_one_file.sh
./combine_read_calculation_into_one_file.sh

# analyse in R
Rscript genome-coverage-between-MP-sliding-window.Rmd



################################################################################


# AIM: run the genome coverage by 5kb window for all contigs that are Hymenoptera

module load R

# copy the file with contigs that are Hymenoptera
cp ~/2019-03-06-minion_flye_QC/result/all_hymenoptera_Ppal_E_contigs tmp/.

# alter it so it becomes contig_XXXX
cut -d "." -f 2 tmp/all_hymenoptera_Ppal_E_contigs > input/all_hymenoptera_Ppal_E_contigs


# make bed files
Rscript make-bed-files.R

# exclude 66x coverage outlier sample
grep -v -E "E15" samples > samples-without-E15

# remove the contigs that are less than 5kb (avoiding segmentation)
cat input/reference_pilon_pilon.fasta.fai | awk '{if($2 > 5000) print $1}' | sed 's/_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon//g' > tmp/5kb_Ppal_E_contigs

# remove the contigs that are not Hymenoptera
grep -f input/all_hymenoptera_Ppal_E_contigs tmp/5kb_Ppal_E_contigs > tmp/5kb_hymenoptera_Ppal_E_contigs

# rerun make bed files for those files
Rscript make-bed-files.R

# calculate mean (here I change the variables for all contigs)
cp calculate_mean_for_10_contigs.sh calculate_mean_for_all_contigs.sh
qsub calculate_mean_for_all_contigs.sh

# combine read calculation in one file
cp combine_read_calculation_into_one_file.sh combine_all_read_calculation_into_one_file.sh
./combine_all_read_calculation_into_one_file.sh

# analyse in R to make the figure
cp genome-coverage-between-MP-sliding-window.Rmd genome-coverage-all-between-MP-sliding-window.Rmd

# contigs to investigate:
# - those are smaller than 5kb
# - those listed in genome-coverage-all-between-MP-sliding-window.Rmd


################################################################################
####
# aim: obtaining site-per-site pairwise FST values (coding and non-coding)

todayanalysis="2020-01-20-fst"

module load plink

# case-control should be defined as 0 - 1
# here pheno has 1 - 2, hopefully this works too
plink --vcf result/2019-03-14-bruniquel-maf10percent.recode.vcf \
      --allow-extra-chr \
      --allow-no-sex \
      --fst \
      --within pheno.txt \
      --pheno pheno.txt \
      --out result/${todayanalysis}


# to be used in R script for making MS pub - per locus, the figure is quite busy

# aim: obtaining 5kb window pairwise FST values (coding and non-coding)

module load vcftools

vcftools --vcf result/2019-03-14-bruniquel-maf10percent.recode.vcf \
         --weir-fst-pop monogynous-samples-from-vcf \
         --weir-fst-pop polygynous-samples-from-vcf \
         --fst-window-size 5000 \
         --out result/2020-01-22-bruniquel-m-vs-p-5kb

# 2020-01-22-bruniquel-m-vs-p-5kb.windowed.weir.fst to be used in R script



# aim: how many reads are non-reference for any given locus?
# for three contigs: contig_4557, contig_3700, contig_1470
# for two samples: A57-M and A09-P

cd 2019-03-14-bruniquel-maf10percent

# update few things here
# scratch space now is:
mkdir -p ~/scratch/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent

unlink tmp

ln -s ~/scratch/2019-03-05-association_analysis_flye_assembly/2019-03-14-bruniquel-maf10percent tmp

module load bcftools

# vcf needs to be bgzip
bgzip -c ../2019-03-07-variant_calling/result/minionflye-115samples-less_alleles.vcf > tmp/minionflye-115samples-less_alleles.vcf

# vcf needs to be indexed
tabix -p vcf tmp/minionflye-115samples-less_alleles.vcf

# subset VCF
bcftools query --regions contig_4557_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon,contig_3700_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon,contig_1470_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon_pilon \
               --samples A57-M,A09-P \
               --format '%CHROM\t%POS[\t%GT\t%DP]\n' \
               tmp/minionflye-115samples-less_alleles.vcf \
               > tmp/2020-02-17-read-balance-query

# save it to result
mv tmp/2020-02-17-read-balance-query result/2020-02-17-read-balance-query
